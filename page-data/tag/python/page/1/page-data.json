{"componentChunkName":"component---src-templates-tag-template-js","path":"/tag/python/page/1","result":{"data":{"site":{"siteMetadata":{"title":"Tôi là Duyệt","subtitle":"Data Engineer @ Fossil. I blog about web development, machine learning, data engineering and more."}},"allMarkdownRemark":{"edges":[{"node":{"fields":{"slug":"/2017/04/nlp-truyen-kieu-word2vec.html","categorySlug":"/category/machine-learning/"},"frontmatter":{"title":"NLP - Truyện Kiều Word2vec","date":"2017-04-16T23:44:00.000+07:00","category":"Machine Learning","description":"Trong các dự án gần đây mình làm nhiều về Word2vec, khá có vẻ là useful trong việc biểu diễn word lên không gian vector (word embedding). Nói thêm về Word2vec, trong các dự án nghiên cứu W2V của Google còn khám phá được ra tính ngữ nghĩa, cú pháp của các từ ở một số mức độ nào đó","thumbnail":"https://1.bp.blogspot.com/-O7tdQkuYZ4U/WPOFQVmaFaI/AAAAAAAAkmE/B_LuJ3fxknYsAekzZCy5uOLez3znOiV9wCK4B/s1600/word2vectors.gif"}}},{"node":{"fields":{"slug":"/2017/03/python-churn-prediction-with-graphlab.html","categorySlug":"/category/machine-learning/"},"frontmatter":{"title":"Python - Churn prediction with Graphlab","date":"2017-03-18T11:24:00.001+07:00","category":"Machine Learning","description":"Churn prediction is the task of identifying whether users are likely to stop using a service, product, or website. With Graphlab toolkit, you can start with raw (or processed) usage metrics and accurately forecast the probability that a given customer will churn.","thumbnail":"https://3.bp.blogspot.com/-QM-iDbzDDHA/WMyzyHEo0bI/AAAAAAAAkLg/xshMvTyQvmYvUQMzROiW4NOmuewyGoXfACK4B/s1600/churn-illustration.png"}}},{"node":{"fields":{"slug":"/2016/12/vntokenizer-tren-pyspark.html","categorySlug":"/category/data-engineer/"},"frontmatter":{"title":"vnTokenizer trên PySpark","date":"2016-12-14T08:00:00.001+07:00","category":"Data Engineer","description":"Trong blog này mình sẽ custom lại vn.vitk để có thể chạy như một thư viện lập trình, sử dụng ngôn ngữ python (trên PySpark và Jupyter Notebook).","thumbnail":null}}},{"node":{"fields":{"slug":"/2016/11/r-tren-jupiter-notebook-ubuntu-1404.html","categorySlug":"/category/data-engineer/"},"frontmatter":{"title":"R trên Jupiter Notebook (Ubuntu 14.04 / 14.10 / 16.04)","date":"2016-11-22T23:53:00.000+07:00","category":"Data Engineer","description":"Jupyter Notebook là công cụ khá mạnh của lập trình viên Python và Data Science. Nếu dùng R, Jupyter cũng cho phép ta tích hợp R kernel vào Notebook một cách dễ dàng.","thumbnail":"https://4.bp.blogspot.com/-aQIMnwL9Gxc/WDR00IF9dqI/AAAAAAAAf9w/ZvplzJNUtI8vjWh2nF8_kVJZoYF3fHF9QCLcB/s1600/Screenshot%2Bfrom%2B2016-11-22%2B23-39-25.png"}}},{"node":{"fields":{"slug":"/2016/10/devstack-maruno-magnum.html","categorySlug":"/category/news/"},"frontmatter":{"title":"Openstack - App Catalog và Docker trên Devstack","date":"2016-10-29T18:46:00.000+07:00","category":"News","description":"DevStack là giúp triển khai mô hình Openstack cho Developers, có thể chạy trên Single-Machine","thumbnail":"https://2.bp.blogspot.com/-8mDGZPymnKU/WBSIXCWaybI/AAAAAAAAfaM/pIubRdw6SrkJLB4Sm8oLQJ1D7quLU8rxwCEw/s1600/Screenshot%2Bfrom%2B2016-10-29%2B18-28-55.png"}}},{"node":{"fields":{"slug":"/2016/09/spark-convert-text-csv-to-parquet.html","categorySlug":"/category/data-engineer/"},"frontmatter":{"title":"Spark: Convert Text (CSV) to Parquet để tối ưu hóa Spark SQL và HDFS","date":"2016-09-21T10:54:00.000+07:00","category":"Data Engineer","description":"Lưu trữ dữ liệu dưới dạng Columnar như Apache Parquet góp phần tăng hiệu năng truy xuất trên Spark lên rất nhiều lần. Bởi vì nó có thể tính toán và chỉ lấy ra 1 phần dữ liệu cần thiết (như 1 vài cột trên CSV), mà không cần phải đụng tới các phần khác của data row. Ngoài ra Parquet còn hỗ trợ flexible compression do đó tiết kiệm được rất nhiều không gian HDFS.","thumbnail":"https://2.bp.blogspot.com/-e_wBjtB6Fl0/V-ID3ys6F9I/AAAAAAAAd_k/jRxF8H344KM_ywgsxVfQAPy3GDXAd1_fQCK4B/s1600/parquet-logo.png"}}},{"node":{"fields":{"slug":"/2016/09/chay-apache-spark-voi-jupyter-notebook.html","categorySlug":"/category/data/"},"frontmatter":{"title":"Chạy Apache Spark với Jupyter Notebook","date":"2016-09-20T14:36:00.001+07:00","category":"Data","description":"IPython Notebook là một công cụ tiện lợi cho Python. Ta có thể Debug chương trình PySpark Line-by-line trên IPython Notebook một cách dễ dàng, tiết kiệm được nhiều thời gian.","thumbnail":"https://1.bp.blogspot.com/-IbzOyRw7mkM/V-Dm-cyXE9I/AAAAAAAAd-I/nGA92fFap4MM4uqKErB7g2H-t6T7CD1RQCLcB/s1600/Selection_006.png"}}},{"node":{"fields":{"slug":"/2016/09/pyspark-thieu-thu-vien-python-tren-worker.html","categorySlug":"/category/data/"},"frontmatter":{"title":"PySpark - Thiếu thư viện Python trên Worker","date":"2016-09-08T09:55:00.000+07:00","category":"Data","description":"Apache Spark chạy trên Cluster, với Java thì đơn giản. Với Python thì package python phải được cài trên từng Node của Worker. Nếu không bạn sẽ gặp phải lỗi thiếu thư viện.","thumbnail":null}}}]}},"pageContext":{"tag":"Python","currentPage":1,"postsLimit":8,"postsOffset":8,"prevPagePath":"/tag/python","nextPagePath":"/tag/python/page/2","hasPrevPage":true,"hasNextPage":true}},"staticQueryHashes":["251939775","2672868365","401334301"]}