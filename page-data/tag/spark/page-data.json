{"componentChunkName":"component---src-templates-tag-template-js","path":"/tag/spark","result":{"data":{"site":{"siteMetadata":{"title":"Tôi là Duyệt","subtitle":"Data Engineer @ Fossil. I blog about web development, machine learning, data engineering and more."}},"allMarkdownRemark":{"edges":[{"node":{"fields":{"slug":"/2020/10/why-spark-on-kubernetes.html","categorySlug":"/category/data-engineer/"},"frontmatter":{"title":"Tại sao nên triển khai Apache Spark trên Kubernetes","date":"2020-10-24T00:00:00.000+07:00","category":"Data Engineer","description":"Spark đã quá nổi tiếng trong thế giới Data Engineering và Bigdata. Kubernetes cũng ngày càng phổ biến tương tự, là một hệ thống quản lý deployment và scaling application. Bài viết này bàn đến một số lợi ích khi triển khai ứng dụng Apache Spark trên hệ thống Kubernetes.","thumbnail":"https://1.bp.blogspot.com/-aBPAW0o9sqY/X5Ps-9d_hLI/AAAAAAABp1A/ZCTOfwThNEUykd4biRSDnZj0D7menY9kACLcBGAsYHQ/s0/spark-on-k8s.jpg"}}},{"node":{"fields":{"slug":"/2020/05/spark-history-server-on-k8s.html","categorySlug":"/category/data-engineer/"},"frontmatter":{"title":"Spark History Server on Kubernetes","date":"2020-05-29T11:00:00.000+07:00","category":"Data Engineer","description":"The problem with running Spark on Kubernetes is the logs go away once the job completes. Spark has tool called the Spark History Server that provides a UI for your past Spark jobs. In this post, I will show you how to use Spark History Server on Kubernetes.","thumbnail":"https://2.bp.blogspot.com/-BOTA2PWkjBY/XtIGGKlRVGI/AAAAAAABZ0g/xvQ-OCIjSHM6gIkKeXn1ORPG1m32mCkiQCK4BGAYYCw/s1600/spark-history-server.png"}}},{"node":{"fields":{"slug":"/2020/05/spark-on-k8s.html","categorySlug":"/category/data-engineer/"},"frontmatter":{"title":"3 ways to run Spark on Kubernetes","date":"2020-05-24T11:00:00.000+07:00","category":"Data Engineer","description":"Spark can run on clusters managed by Kubernetes. This feature makes use of native Kubernetes scheduler that has been added to Spark.","thumbnail":"https://1.bp.blogspot.com/-VI84ABaeYlc/XtIGszW5AoI/AAAAAAABZ0s/w1MDUsBNLwsB7_gMIKf-WMX5JXfZOnXLACK4BGAYYCw/s1600/livy-spark-k8s.png"}}},{"node":{"fields":{"slug":"/2017/05/cai-apache-spark-standalone-ban-pre.html","categorySlug":"/category/data/"},"frontmatter":{"title":"Cài Apache Spark standalone bản pre-built","date":"2017-05-31T22:19:00.001+07:00","category":"Data","description":"Mình nhận được nhiều phản hồi từ bài viết BigData - Cài đặt Apache Spark trên Ubuntu 14.04 rằng sao cài khó và phức tạp thế. Thực ra bài viết đó mình hướng dẫn cách build và install từ source.","thumbnail":"https://4.bp.blogspot.com/-5hwfzlugnac/WS7b6rg8cQI/AAAAAAAAlDg/Rgpp6oj-lGQludEAlYo9YtOrGCeudR0zgCLcB/s1600/Screenshot%2Bfrom%2B2017-05-31%2B22-02-05.png"}}},{"node":{"fields":{"slug":"/2016/12/vntokenizer-tren-pyspark.html","categorySlug":"/category/data-engineer/"},"frontmatter":{"title":"vnTokenizer trên PySpark","date":"2016-12-14T08:00:00.001+07:00","category":"Data Engineer","description":"Trong blog này mình sẽ custom lại vn.vitk để có thể chạy như một thư viện lập trình, sử dụng ngôn ngữ python (trên PySpark và Jupyter Notebook).","thumbnail":null}}},{"node":{"fields":{"slug":"/2016/09/chay-apache-spark-voi-jupyter-notebook.html","categorySlug":"/category/data/"},"frontmatter":{"title":"Chạy Apache Spark với Jupyter Notebook","date":"2016-09-20T14:36:00.001+07:00","category":"Data","description":"IPython Notebook là một công cụ tiện lợi cho Python. Ta có thể Debug chương trình PySpark Line-by-line trên IPython Notebook một cách dễ dàng, tiết kiệm được nhiều thời gian.","thumbnail":"https://1.bp.blogspot.com/-IbzOyRw7mkM/V-Dm-cyXE9I/AAAAAAAAd-I/nGA92fFap4MM4uqKErB7g2H-t6T7CD1RQCLcB/s1600/Selection_006.png"}}},{"node":{"fields":{"slug":"/2016/09/pyspark-thieu-thu-vien-python-tren-worker.html","categorySlug":"/category/data/"},"frontmatter":{"title":"PySpark - Thiếu thư viện Python trên Worker","date":"2016-09-08T09:55:00.000+07:00","category":"Data","description":"Apache Spark chạy trên Cluster, với Java thì đơn giản. Với Python thì package python phải được cài trên từng Node của Worker. Nếu không bạn sẽ gặp phải lỗi thiếu thư viện.","thumbnail":null}}},{"node":{"fields":{"slug":"/2015/07/big-data-monitoring-spark-with-graphite.html","categorySlug":"/category/news/"},"frontmatter":{"title":"Big Data - Monitoring Spark with Graphite and Grafana","date":"2015-07-14T12:58:00.001+07:00","category":"News","description":null,"thumbnail":"https://3.bp.blogspot.com/-ytrI0VvmxgE/VaSiReFjsmI/AAAAAAAACl0/JSOfOs9-Pas/s1600/ss-tasks-3.png"}}}]}},"pageContext":{"tag":"Spark","currentPage":0,"postsLimit":8,"postsOffset":0,"prevPagePath":"/tag/spark","nextPagePath":"/tag/spark/page/1","hasPrevPage":false,"hasNextPage":true}},"staticQueryHashes":["251939775","2672868365","401334301"]}