{"componentChunkName":"component---src-templates-tag-template-js","path":"/tag/data-engineer/page/3","result":{"data":{"site":{"siteMetadata":{"title":"Tôi là Duyệt","subtitle":"Data Engineer @ Fossil. I blog about web development, machine learning, data engineering and more."}},"allMarkdownRemark":{"edges":[{"node":{"fields":{"slug":"/2017/08/natural-nltk.html","categorySlug":"/category/machine-learning/"},"frontmatter":{"title":"natural - NLTK cho Javascript","date":"2017-08-06T11:38:00.000+07:00","category":"Machine Learning","description":"NaturalJS được ví như nltk cho Node. natural có nhiều chức năng xử lý ngôn ngữ tự nhiên như: Tokenizing, stemming, classification, phonetics, tf-idf, WordNet, string similarity, ...","thumbnail":"https://4.bp.blogspot.com/-7UyZjfbL--g/WYadFDYvEfI/AAAAAAAAmc4/x-jU5zgVZz8BsBM5VP5zkZA5Y8c79XIBQCK4BGAYYCw/s1600/nlp_js.png"}}},{"node":{"fields":{"slug":"/2017/05/cai-apache-spark-standalone-ban-pre.html","categorySlug":"/category/data/"},"frontmatter":{"title":"Cài Apache Spark standalone bản pre-built","date":"2017-05-31T22:19:00.001+07:00","category":"Data","description":"Mình nhận được nhiều phản hồi từ bài viết BigData - Cài đặt Apache Spark trên Ubuntu 14.04 rằng sao cài khó và phức tạp thế. Thực ra bài viết đó mình hướng dẫn cách build và install từ source.","thumbnail":"https://4.bp.blogspot.com/-5hwfzlugnac/WS7b6rg8cQI/AAAAAAAAlDg/Rgpp6oj-lGQludEAlYo9YtOrGCeudR0zgCLcB/s1600/Screenshot%2Bfrom%2B2017-05-31%2B22-02-05.png"}}},{"node":{"fields":{"slug":"/2017/04/nlp-truyen-kieu-word2vec.html","categorySlug":"/category/machine-learning/"},"frontmatter":{"title":"NLP - Truyện Kiều Word2vec","date":"2017-04-16T23:44:00.000+07:00","category":"Machine Learning","description":"Trong các dự án gần đây mình làm nhiều về Word2vec, khá có vẻ là useful trong việc biểu diễn word lên không gian vector (word embedding). Nói thêm về Word2vec, trong các dự án nghiên cứu W2V của Google còn khám phá được ra tính ngữ nghĩa, cú pháp của các từ ở một số mức độ nào đó","thumbnail":"https://1.bp.blogspot.com/-O7tdQkuYZ4U/WPOFQVmaFaI/AAAAAAAAkmE/B_LuJ3fxknYsAekzZCy5uOLez3znOiV9wCK4B/s1600/word2vectors.gif"}}},{"node":{"fields":{"slug":"/2017/02/learning-r-cheatsheet.html","categorySlug":"/category/machine-learning/"},"frontmatter":{"title":"Learning R cheatsheet","date":"2017-02-05T12:26:00.000+07:00","category":"Machine Learning","description":"R cheatsheet","thumbnail":null}}},{"node":{"fields":{"slug":"/2017/01/rancher.html","categorySlug":"/category/linux/"},"frontmatter":{"title":"Rancher - Quản lý Docker Container bằng UI","date":"2017-01-23T13:32:00.000+07:00","category":"Linux","description":"Rancher giúp quản lý Docker bằng UI Web một cách tiện dụng, mọi thao tác đều trên UI. Rancher còn tích hợp Shell trên Docker, App catalog, ...","thumbnail":"https://3.bp.blogspot.com/-QUh_PaavDSA/WIWWTCtiTXI/AAAAAAAAies/LvVHTtMjnAglcdCB8uZfGsgJVfz7dirXQCLcB/s1600/ezgif.com-optimize.gif"}}},{"node":{"fields":{"slug":"/2016/12/vntokenizer-tren-pyspark.html","categorySlug":"/category/data-engineer/"},"frontmatter":{"title":"vnTokenizer trên PySpark","date":"2016-12-14T08:00:00.001+07:00","category":"Data Engineer","description":"Trong blog này mình sẽ custom lại vn.vitk để có thể chạy như một thư viện lập trình, sử dụng ngôn ngữ python (trên PySpark và Jupyter Notebook).","thumbnail":null}}},{"node":{"fields":{"slug":"/2016/11/r-tren-jupiter-notebook-ubuntu-1404.html","categorySlug":"/category/data-engineer/"},"frontmatter":{"title":"R trên Jupiter Notebook (Ubuntu 14.04 / 14.10 / 16.04)","date":"2016-11-22T23:53:00.000+07:00","category":"Data Engineer","description":"Jupyter Notebook là công cụ khá mạnh của lập trình viên Python và Data Science. Nếu dùng R, Jupyter cũng cho phép ta tích hợp R kernel vào Notebook một cách dễ dàng.","thumbnail":"https://4.bp.blogspot.com/-aQIMnwL9Gxc/WDR00IF9dqI/AAAAAAAAf9w/ZvplzJNUtI8vjWh2nF8_kVJZoYF3fHF9QCLcB/s1600/Screenshot%2Bfrom%2B2016-11-22%2B23-39-25.png"}}},{"node":{"fields":{"slug":"/2016/09/spark-convert-text-csv-to-parquet.html","categorySlug":"/category/data-engineer/"},"frontmatter":{"title":"Spark: Convert Text (CSV) to Parquet để tối ưu hóa Spark SQL và HDFS","date":"2016-09-21T10:54:00.000+07:00","category":"Data Engineer","description":"Lưu trữ dữ liệu dưới dạng Columnar như Apache Parquet góp phần tăng hiệu năng truy xuất trên Spark lên rất nhiều lần. Bởi vì nó có thể tính toán và chỉ lấy ra 1 phần dữ liệu cần thiết (như 1 vài cột trên CSV), mà không cần phải đụng tới các phần khác của data row. Ngoài ra Parquet còn hỗ trợ flexible compression do đó tiết kiệm được rất nhiều không gian HDFS.","thumbnail":"https://2.bp.blogspot.com/-e_wBjtB6Fl0/V-ID3ys6F9I/AAAAAAAAd_k/jRxF8H344KM_ywgsxVfQAPy3GDXAd1_fQCK4B/s1600/parquet-logo.png"}}}]}},"pageContext":{"tag":"Data Engineer","currentPage":3,"postsLimit":8,"postsOffset":24,"prevPagePath":"/tag/data-engineer/page/2","nextPagePath":"/tag/data-engineer/page/4","hasPrevPage":true,"hasNextPage":true}},"staticQueryHashes":["251939775","2672868365","401334301"]}