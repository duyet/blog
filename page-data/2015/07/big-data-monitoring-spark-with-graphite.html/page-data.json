{"componentChunkName":"component---src-templates-post-template-tsx","path":"/2015/07/big-data-monitoring-spark-with-graphite.html","result":{"data":{"markdownRemark":{"id":"565c3889-31dc-5650-a2ea-8bc4a37b2a08","html":"<p>This post I have read from <a href=\"http://www.hammerlab.org/2015/02/27/monitoring-spark-with-graphite-and-grafana/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">HammerLab</a>, Contact me if Vietnamese version neccessary. In this post, they’ll discuss using Graphite and Grafana to graph metrics obtained from our <a href=\"http://spark.apache.org/docs/1.2.1/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Spark</a> applications to answer these questions</p>\n<p><a href=\"https://3.bp.blogspot.com/-ytrI0VvmxgE/VaSiReFjsmI/AAAAAAAACl0/JSOfOs9-Pas/s1600/ss-tasks-3.png\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><img src=\"https://3.bp.blogspot.com/-ytrI0VvmxgE/VaSiReFjsmI/AAAAAAAACl0/JSOfOs9-Pas/s1600/ss-tasks-3.png\"></a></p>\n<blockquote>\n<p>At Hammer Lab, we use Spark to run analyses of genomic data in a distributed fashion. Distributed programs present unique challenges related to monitoring and debugging of code. Many standard approaches to fundamental questions of programming (what is my program doing? Why did it do what it did?) do not apply in a distributed context, leading to considerable frustration and despair.</p>\n</blockquote>\n<p>In this post, we’ll discuss using <a href=\"http://graphite.readthedocs.org/en/latest/overview.html\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Graphite</a> and <a href=\"http://grafana.org/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Grafana</a> to graph metrics obtained from our Spark applications to answer these questions.</p>\n<p>Graphs of various metrics about the progress of a Spark application; read on for more info. </p>\n<h2 id=\"spark-web-ui\" style=\"position:relative;\"><a href=\"#spark-web-ui\" aria-label=\"spark web ui permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Spark Web UI</h2>\n<p>Spark ships with a <a href=\"http://eclipse.org/jetty/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Jetty</a> server that provides a wealth of information about running applications:</p>\n<p><img src=\"https://4.bp.blogspot.com/-sXafwlnZE8I/VaSixijiOJI/AAAAAAAACl8/9gEn1oCZlPU/s1600/spark-web-ui.png\"></p>\n<p>Here we see a page with information about a specific stage in a job: completed tasks, metrics per executor, and (below the fold) metrics per task.</p>\n<p>This interface seems to be the way that most users interact with Spark applications. It gives a good overview of the state of an application and allows for drilling into certain metrics, such as bytes read from HDFS or time spent <a href=\"http://en.wikipedia.org/wiki/Garbage_collection_%28computer_science%29\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">garbage collecting</a>.</p>\n<p>However, we hit <a href=\"https://issues.apache.org/jira/browse/SPARK-2017\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">issues</a> with its ability to <a href=\"https://issues.apache.org/jira/browse/SPARK-4598\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">scale</a> and its <a href=\"https://issues.apache.org/jira/browse/SPARK-5106\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">real-time experience</a>. Recognizing that reasonable people can (<a href=\"https://github.com/apache/spark/pull/2342\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">and do!</a>) <a href=\"https://issues.apache.org/jira/browse/SPARK-2132\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">disagree</a> about <a href=\"https://issues.apache.org/jira/browse/SPARK-1832\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">subjective preferences related to such UIs</a>, we sought a platform that better allowed us to experiment with ways to monitor our applications.</p>\n<h2 id=\"enter-metricssystem\" style=\"position:relative;\"><a href=\"#enter-metricssystem\" aria-label=\"enter metricssystem permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Enter: <a href=\"https://github.com/apache/spark/blob/9f603fce78fcc997926e9a72dec44d48cbc396fc/core/src/main/scala/org/apache/spark/metrics/MetricsSystem.scala\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">MetricsSystem</a></h2>\n<p>Buried in a rarely-explored corner of the Spark codebase is a component called <a href=\"https://github.com/apache/spark/blob/9f603fce78fcc997926e9a72dec44d48cbc396fc/core/src/main/scala/org/apache/spark/metrics/MetricsSystem.scala\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">MetricsSystem</a>. A MetricsSystem instance lives on every driver and executor and optionally exposes metrics to a variety of <a href=\"https://github.com/apache/spark/blob/9f603fce78fcc997926e9a72dec44d48cbc396fc/core/src/main/scala/org/apache/spark/metrics/sink/Sink.scala\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Sink</a>s while applications are running. </p>\n<p>In this way, MetricsSystem offers the freedom to monitor Spark applications using a variety of third-party tools.</p>\n<h3 id=\"graphite\" style=\"position:relative;\"><a href=\"#graphite\" aria-label=\"graphite permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Graphite</h3>\n<p>In particular, MetricsSystem includes <a href=\"https://github.com/apache/spark/blob/9f603fce78fcc997926e9a72dec44d48cbc396fc/core/src/main/scala/org/apache/spark/metrics/sink/GraphiteSink.scala\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">bindings</a> to ship metrics to <a href=\"http://graphite.readthedocs.org/en/latest/overview.html\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Graphite</a>, a popular open-source tool for collecting and serving time series data. </p>\n<p>This capability is <a href=\"http://spark.apache.org/docs/1.2.1/monitoring.html#metrics\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">discussed briefly</a> in the Spark docs, but there is little to no information on the internet about anyone <a href=\"http://stackoverflow.com/questions/23529404/spark-on-yarn-how-to-send-metrics-to-graphite-sink\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">using it</a>, so here is a quick digression about how to get Spark to report metrics to Graphite.</p>\n<h3 id=\"sending-metrics-spark-→-graphite\" style=\"position:relative;\"><a href=\"#sending-metrics-spark-%E2%86%92-graphite\" aria-label=\"sending metrics spark → graphite permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Sending Metrics: Spark → Graphite</h3>\n<p>Spark’s MetricsSystem is configured via a metrics.properties file; Spark ships with a <a href=\"https://github.com/apache/spark/blob/9f603fce78fcc997926e9a72dec44d48cbc396fc/conf/metrics.properties.template\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">template</a> that provides examples of configuring a variety of <a href=\"https://github.com/apache/spark/blob/9f603fce78fcc997926e9a72dec44d48cbc396fc/core/src/main/scala/org/apache/spark/metrics/source/Source.scala\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Source</a>s and <a href=\"https://github.com/apache/spark/blob/9f603fce78fcc997926e9a72dec44d48cbc396fc/core/src/main/scala/org/apache/spark/metrics/sink/Sink.scala\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Sink</a>s. <a href=\"https://gist.github.com/ryan-williams/9bf8ae842e02dbc9ab93\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Here</a> is an example like the one we use. Set up a metrics.properties file for yourself, accessible from the machine you’ll be starting your Spark job from.</p>\n<p>Next, pass the following flags to <a href=\"https://github.com/apache/spark/blob/9f603fce78fcc997926e9a72dec44d48cbc396fc/bin/spark-submit\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><code class=\"language-text\">spark-submit</code></a>:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">--files=/path/to/metrics.properties \\\n--conf spark.metrics.conf=metrics.properties</code></pre></div>\n<p>The <code class=\"language-text\">--files</code> flag will cause <code class=\"language-text\">/path/to/metrics.properties</code> to be sent to every executor, and <code class=\"language-text\">spark.metrics.conf=metrics.properties</code> will tell all executors to load that file when initializing their respective <code class=\"language-text\">MetricsSystem</code>s.</p>\n<h3 id=\"grafana\" style=\"position:relative;\"><a href=\"#grafana\" aria-label=\"grafana permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Grafana</h3>\n<p>Having thus configured Spark (and installed Graphite), we surveyed <a href=\"http://graphite.readthedocs.org/en/latest/tools.html#visualization\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">the many Graphite-visualization tools that exist</a> and began building custom Spark-monitoring dashboards using <a href=\"http://grafana.org/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Grafana</a>. Grafana is “an open source, feature rich metrics dashboard and graph editor for Graphite, InfluxDB &#x26; OpenTSDB,” and includes some powerful features for <a href=\"http://grafana.org/docs/features/scripted_dashboards/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">scripting</a> the creation of <a href=\"http://grafana.org/docs/features/templated_dashboards/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">dynamic</a> dashboards, allowing us to experiment with many ways of visualizing the performance of our Spark applications in real-time.</p>\n<h1 id=\"examples--examples\" style=\"position:relative;\"><a href=\"#examples--examples\" aria-label=\"examples  examples permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Examples # (#examples)</h1>\n<p>Below are a few examples illustrating the kinds of rich information we can get from this setup.</p>\n<h2 id=\"task-completion-rate--task-completion-rate\" style=\"position:relative;\"><a href=\"#task-completion-rate--task-completion-rate\" aria-label=\"task completion rate  task completion rate permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Task Completion Rate ## (#task-completion-rate)</h2>\n<p>These graphs show the number of active and completed tasks, per executor and overall, from a successful test of some toy <a href=\"https://github.com/hammerlab/guacamole/blob/5e060ae0e13434e42477ae0715e92103ab45baf9/src/main/scala/org/hammerlab/guacamole/commands/ReadDepthHist.scala\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">read depth histogram</a> functionality in a branch of our <a href=\"https://github.com/hammerlab/guacamole\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Guacamole</a> variant calling project:</p>\n<p><img src=\"https://3.bp.blogspot.com/-053jp9eCxuk/VaSkFFqSPcI/AAAAAAAACmI/9xw3c4rM20Y/s1600/rdh-tasks.png\"></p>\n<p>The leftmost panel shows close to 400 tasks in flight at once, which  in this application corresponds to 4 “cores” on each of 100 executors.  The “valley” in that leftmost panel corresponds to the transition  between two stages of the one job in this application.\nThe right two panels show the number of tasks completed and rate of task completion per minute for each executor.</p>\n<h2 id=\"hdfs-io--hdfs-io\" style=\"position:relative;\"><a href=\"#hdfs-io--hdfs-io\" aria-label=\"hdfs io  hdfs io permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>HDFS I/O ## (#hdfs-io)</h2>\n<p><code class=\"language-text\">MetricsSystem</code> also reports all filesystem- and HDFS-I/O  at per-executor granularity. Below are some graphs showing us our  application’s HDFS read statistics:</p>\n<p><img src=\"https://4.bp.blogspot.com/-4-cphPMQd1g/VaSkMWsiwLI/AAAAAAAACmQ/txn9hIoOnt4/s1600/hdfs-graphs.png\"></p>\n<p>Clockwise from top left, we see:</p>\n<ul>\n<li>a peak of ~100 HDFS reads per second (red line, right Y-axis),  with individual executors topping out around ~2/s over any given 10s  interval (thinner multi-colored lines),</li>\n<li>a total of ~700 HDFS reads (red line, right Y-axis) over the  application’s lifespan, with individual executors accounting for  anywhere from ~20 to ~100,</li>\n<li>a total of ~180 GB of data read from HDFS  (red line, right Y-axis), which is in line with what was expected from this job, and</li>\n<li>a peak total read throughput of around 1.5 GB/s.</li>\n</ul>\n<p>Our applications are typically not I/O bound in any meaningful way,  but we’ve nonetheless found access to such information useful, if only  from a sanity-checking perspective.</p>\n<h2 id=\"jvm--jvm\" style=\"position:relative;\"><a href=\"#jvm--jvm\" aria-label=\"jvm  jvm permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>JVM ## (#jvm)</h2>\n<p>The <a href=\"https://github.com/apache/spark/blob/9f603fce78fcc997926e9a72dec44d48cbc396fc/core/src/main/scala/org/apache/spark/metrics/source/JvmSource.scala\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">JVM statistics exported by Spark</a> are a treasure trove of information about what is going on in each  executor. We’ve only begun to experiment with ways to distill this data;  here’s an example of per-executor panels with information about garbage  collection:</p>\n<p><img src=\"https://3.bp.blogspot.com/-v1FutiNm7l8/VaSkTzHm34I/AAAAAAAACmY/rIdDEL5LVkY/s1600/per-executor-jvm-metrics.png\"></p>\n<h1 id=\"case-study-ill-fated-somaticstandard-run--case-study-ill-fated-somaticstandardsomaticstandard-run\" style=\"position:relative;\"><a href=\"#case-study-ill-fated-somaticstandard-run--case-study-ill-fated-somaticstandardsomaticstandard-run\" aria-label=\"case study ill fated somaticstandard run  case study ill fated somaticstandardsomaticstandard run permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Case Study: Ill-Fated <a href=\"https://github.com/hammerlab/guacamole/blob/4c0381c6feba189ab605decaaea3c56a158ff565/src/main/scala/org/hammerlab/guacamole/commands/SomaticStandardCaller.scala\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><code class=\"language-text\">SomaticStandard</code></a> Run # (#case-study-ill-fated-somaticstandardsomaticstandard-run)</h1>\n<p>Let’s do some forensics on a recent failed run of our <a href=\"https://github.com/hammerlab/guacamole/blob/4c0381c6feba189ab605decaaea3c56a158ff565/src/main/scala/org/hammerlab/guacamole/commands/SomaticStandardCaller.scala\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">SomaticStandard variant caller</a> and use our Grafana dashboard to diagnose an issue that proved fatal to the application.\nThe graphs below, similar to those in <a href=\"http://www.hammerlab.org/2015/02/27/monitoring-spark-with-graphite-and-grafana/#task-completion-rate-successful-run\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">the first example above</a>,  show the number of active and completed tasks, per executor and  overall, during a period in the middle of the doomed application’s  lifetime:</p>\n<p><img src=\"https://1.bp.blogspot.com/-Hs2BOfUTPMU/VaSkcnl1tjI/AAAAAAAACmg/qp9LkaQG3uY/s1600/ss-tasks-3.png\"></p>\n<p>From experience, we have learned to note and infer several things from graphs like these:</p>\n<ul>\n<li>All three graphs have a discontinuity toward the middle of the time window presented here.     </li>\n<li>This is likely due to the application master (AM) restarting.</li>\n<li>Related: all “completed tasks per executor” (middle panel) counts restart from zero when the new AM spawns new executors.</li>\n<li>In the lead-up to the discontinuity / AM restart, forward progress had almost completely stopped.     </li>\n<li>The tooltip on the left graph shows that there were several  minutes where only one task (and therefore executor) was active (out of 1000 total executors).</li>\n<li>The “completed task” counts in the right two graphs show no movement.</li>\n<li>Finally, there are a suspicious couple of new lines starting from 0 in the middle graph around 15:31-15:32.     </li>\n<li>Why are executors coming to life this late in the application?</li>\n<li>Answer: these new executors are replacing ones that have been lost.</li>\n<li>Something during this flat-lined period is causing executors to die and be replaced.</li>\n</ul>\n<p>Putting all of this information together, we conclude that the issue here was one of a “hot potato” task inducing <a href=\"http://en.wikipedia.org/wiki/Garbage_collection_%28computer_science%29#Disadvantages\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">garbage collection stalls</a> (and subsequent deaths) in executors that attempted to perform it.\nThis is a common occurrence when <a href=\"http://www.cs.cmu.edu/%7Ekair/papers/bala.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">key skew</a> causes one or a few tasks in a distributed program to be too large  (relative to the amount of memory that has been allocated to the the  executors attempting to process them). The study of skew in MapReduce  systems dates back to the <a href=\"http://static.googleusercontent.com/media/research.google.com/en/us/pubs/archive/32721.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">earliest days of MapReduce at Google</a>, and it is one of the most common causes of mysterious Spark-job-degradation-or-death that we observe today.</p>\n<h1 id=\"grafana-spark-dashboards--grafana-spark-dashboards\" style=\"position:relative;\"><a href=\"#grafana-spark-dashboards--grafana-spark-dashboards\" aria-label=\"grafana spark dashboards  grafana spark dashboards permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><a href=\"https://github.com/hammerlab/grafana-spark-dashboards\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">grafana-spark-dashboards</a> # (#grafana-spark-dashboards)</h1>\n<p>As usual, we’ve open-sourced the tools showcased here in the hopes that you’ll find them useful as well. The <a href=\"https://github.com/hammerlab/grafana-spark-dashboards\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">hammerlab/grafana-spark-dashboards</a> repo contains a script that you should be able to use off-the-shelf to  bootstrap your own slick Grafana dashboards of Spark metrics.</p>\n<h1 id=\"future-work--future-work\" style=\"position:relative;\"><a href=\"#future-work--future-work\" aria-label=\"future work  future work permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Future Work # (#future-work)</h1>\n<p>The development and standardization of sane tools for monitoring and  debugging Spark jobs will be of utmost importance as Spark matures, and  our work thus far represents only a tiny contribution toward that end.\nThough the <a href=\"https://github.com/hammerlab/grafana-spark-dashboards\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">grafana-spark-dashboards</a> previewed above have been useful, there’s still an ocean of relevant  data we would love to get out of Spark and onto our graphs, including  but not limited to:</p>\n<ul>\n<li>Structured information about jobs and stages, particularly start-/end-times and failures.</li>\n<li>Information about what host each executor is running on.</li>\n<li>Task- and record-level metrics!</li>\n<li><a href=\"https://github.com/apache/spark/pull/4067\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Spark #4067</a> added such metrics to the web UI, and it would be great to be able to  see them over time, identify executors / tasks that are lagging, etc.</li>\n<li>Reporting task failures, even one-offs, would be useful; it is  sometimes surprising to behold how many of those occur when perusing  the logs.</li>\n<li><a href=\"http://spark.apache.org/docs/1.2.1/programming-guide.html#accumulators\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">User-defined accumulators</a>.</li>\n</ul>\n<p>In addition, supporting other time series database or metrics collection servers (e.g. <a href=\"https://github.com/apache/spark/pull/4574\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">StatsD</a>, <a href=\"http://influxdb.com/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">InfluxDB</a>, <a href=\"http://opentsdb.net/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">OpenTSDB</a>) would open up more avenues for users to monitor Spark at scale.</p>\n<p>Thanks to <a href=\"https://github.com/ksakellis\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Kostas Sakellis</a> @ Cloudera, <a href=\"https://github.com/ajsquared\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Andrew Johnson</a> @ Etsy, <a href=\"https://github.com/astanway\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Abe Stanway</a>, and <a href=\"https://github.com/torkelo\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Torkel Ödegaard</a> of Grafana/Raintank for their input though this process, and to the Spark team for <a href=\"https://github.com/apache/spark/pull/4212\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">many</a><a href=\"https://github.com/apache/spark/pull/4213\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">recent</a><a href=\"https://github.com/apache/spark/pull/4218\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">MetricsSystem-related</a><a href=\"https://github.com/apache/spark/pull/4571\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code reviews</a>.</p>\n<p><a href=\"http://www.hammerlab.org/2015/02/27/monitoring-spark-with-graphite-and-grafana/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">http://www.hammerlab.org/2015/02/27/monitoring-spark-with-graphite-and-grafana/ </a></p>","fields":{"slug":"/2015/07/big-data-monitoring-spark-with-graphite.html","tagSlugs":["/tag/apache-spark/","/tag/spark/","/tag/big-data/"]},"frontmatter":{"date":"2015-07-14T12:58:00.001+07:00","description":null,"tags":["Apache Spark","Spark","BigData"],"title":"Big Data - Monitoring Spark with Graphite and Grafana","fbCommentUrl":"none"}}},"pageContext":{"slug":"/2015/07/big-data-monitoring-spark-with-graphite.html"}},"staticQueryHashes":["251939775","2672868365","401334301"]}