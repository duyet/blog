{"componentChunkName":"component---src-templates-post-template-js","path":"/2017/10/doc2vec-trong-sentiment-analysis.html","result":{"data":{"markdownRemark":{"id":"7b386c40-273a-5abe-b14f-460358ead75e","html":"<p>Sự thành công của <strong>Word2vec</strong> đã được chứng minh trong rất nhiều công trình NLP.  </p>\n<p>Nhắc lại về Word2vec, nó sử dụng 1 tập copus, qua một mạng Neural biểu diễn các word thành các vector, các vector giữ lại được tính chất ngữ nghĩa. Tức các từ mang ý nghĩa similar với nhau thì gần nhau trong không gian vector. Trong NLP, đây một trong những phương thức của word embedding. Word2vec hiện nay được sử dụng hết sức rộng rãi.  </p>\n<p><strong>Doc2vec</strong>, ngoài từ (word), ta còn có thể biểu diễn các câu (sentences) thậm chí 1 đoạn văn bản (document). Khi đó, bạn có thể dễ dàng vector hóa cả một đoạn văn bản thành một vector có số chiều cố định và nhỏ, từ đó có thể chạy bất cứ thuật toán classification cơ bản nào trên các vector đó.  </p>\n<p><a href=\"https://2.bp.blogspot.com/-IpnvLkBHx74/WdnUJ5r3q_I/AAAAAAAAnxI/Cz9B_YQo6tcu0YwOffsQQWmcfjH_mRulwCK4BGAYYCw/s1600/pv_dm.png\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><img src=\"https://2.bp.blogspot.com/-IpnvLkBHx74/WdnUJ5r3q_I/AAAAAAAAnxI/Cz9B_YQo6tcu0YwOffsQQWmcfjH_mRulwCK4BGAYYCw/s1600/pv_dm.png\"></a>\nẢnh: <a href=\"https://arxiv.org/pdf/1405.4053.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://arxiv.org/pdf/1405.4053.pdf</a></p>\n<p>Trong bài này, mình sẽ giới thiệu rất cơ bản basic concept để các bạn có thể hình dung việc ứng dụng <strong>Doc2vec trong</strong> <strong>Sentiment Analysis</strong> như thế nào.</p>\n<p><strong><a href=\"https://github.com/duyetdev/doc2vec-sentiment/blob/master/Doc2vec%20Sentiment%20Analysis.ipynb\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Xem bài viết dưới dạng notebook.</a></strong>  </p>\n<h2 id=\"doc2vec\" style=\"position:relative;\"><a href=\"#doc2vec\" aria-label=\"doc2vec permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Doc2vec</h2>\n<p><strong>Doc2vec</strong> được giới thiệu bởi <em>Quoc Le</em> và <em>Mikolov</em> (<a href=\"https://arxiv.org/abs/1405.4053\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://arxiv.org/abs/1405.4053</a>), cũng như Word2vec, có 2 model chính là: <strong>DBOW</strong> và <strong>DM</strong>  </p>\n<ul>\n<li>\n<p><strong>DBOW</strong> (distributed bag of words): Mô hình này đơn giản là không quan tâm thứ tự các từ, training nhanh hơn, không sử dụng local-context/neighboring. Mô hình chèn thêm 1 “word” là ParagraphID, ParagraphID này đại diện cho văn bản được training. Sau khi training xong có thể hiểu các vector ParagraphID này là vector embedded của các văn bản. Hình ảnh được mô tả trong bài báo:  </p>\n<p><a href=\"https://3.bp.blogspot.com/-wai3jZmknIY/WdnLxUFOpTI/AAAAAAAAnwc/UfNbC3B1KPw6GxhjIaigYMLnkgyQYAS6QCK4BGAYYCw/s1600/doc2vec_dbow%2B%25281%2529.jpg\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><img src=\"https://3.bp.blogspot.com/-wai3jZmknIY/WdnLxUFOpTI/AAAAAAAAnwc/UfNbC3B1KPw6GxhjIaigYMLnkgyQYAS6QCK4BGAYYCw/s1600/doc2vec_dbow%2B%25281%2529.jpg\"></a></p>\n</li>\n<li>\n<p><strong>DM</strong> (distributed memory): xem một paragraph là một từ, sau đó nối từ này vào tập các từ trong câu. Trong quá trình training, vector của paragraph và vector từ đều được update.  </p>\n<p><a href=\"https://1.bp.blogspot.com/--QeiWTR1UXw/WdnL4u33MoI/AAAAAAAAnwk/_HANkz23v5cgj6gyxWXSQI2X21E7Hc35ACK4BGAYYCw/s1600/doc2vec_dm.jpg\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><img src=\"https://1.bp.blogspot.com/--QeiWTR1UXw/WdnL4u33MoI/AAAAAAAAnwk/_HANkz23v5cgj6gyxWXSQI2X21E7Hc35ACK4BGAYYCw/s1600/doc2vec_dm.jpg\"></a></p>\n</li>\n</ul>\n<p><strong>Tóm lại:</strong> ta xem văn bản như là một từ, docID/paragraphID được biểu diễn dạng 1-hot, được embedded vào không gian vector.  </p>\n<h2 id=\"setup\" style=\"position:relative;\"><a href=\"#setup\" aria-label=\"setup permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Setup</h2>\n<h3 id=\"modules\" style=\"position:relative;\"><a href=\"#modules\" aria-label=\"modules permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Modules</h3>\n<p>Mình sử dụng <strong>gensim</strong>, gensim được implement <strong>Word2vec</strong> lẫn <strong>Doc2vec</strong>, tài liệu rất dễ đọc. Ngoài ra còn có <strong>numpy</strong> để thao tác trên array, <strong>sklearn</strong> cho các thuật toán phân lớp.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token operator\">%</span>matplotlib inline\n\n<span class=\"token comment\"># gensim modules</span>\n<span class=\"token keyword\">from</span> gensim <span class=\"token keyword\">import</span> utils\n<span class=\"token keyword\">from</span> gensim<span class=\"token punctuation\">.</span>models<span class=\"token punctuation\">.</span>doc2vec <span class=\"token keyword\">import</span> LabeledSentence\n<span class=\"token keyword\">from</span> gensim<span class=\"token punctuation\">.</span>models <span class=\"token keyword\">import</span> Doc2Vec\n\n<span class=\"token comment\"># numpy</span>\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n\n<span class=\"token comment\"># classifier</span>\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>linear_model <span class=\"token keyword\">import</span> LogisticRegression\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>svm <span class=\"token keyword\">import</span> SVC\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>metrics <span class=\"token keyword\">import</span> confusion_matrix\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>metrics <span class=\"token keyword\">import</span> accuracy_score\n\n<span class=\"token comment\"># random, itertools, matplotlib</span>\n<span class=\"token keyword\">import</span> random\n<span class=\"token keyword\">import</span> itertools\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt</code></pre></div>\n<h3 id=\"data\" style=\"position:relative;\"><a href=\"#data\" aria-label=\"data permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Data</h3>\n<p>Mình có các tập data để training, gồm training và testing như sau:</p>\n<ul>\n<li><em>test-neg.txt:</em> 12500 negative movie reviews from the test data</li>\n<li><em>test-pos.txt</em>: 12500 positive movie reviews from the test data</li>\n<li><em>train-neg.txt</em>: 12500 negative movie reviews from the training data</li>\n<li><em>train-pos.txt</em>: 12500 positive movie reviews from the training data</li>\n</ul>\n<p>Tải dataset tại đây: <strong><a href=\"https://github.com/duyetdev/doc2vec-sentiment\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Github</a></strong>  </p>\n<p>Trong mỗi file data, 1 đoạn văn bản trên một dòng:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">once again mr costner has dragged out a movie for far longer than necessary aside from the terrific sea rescue sequences of...\nthis is an example of why the majority of action films are the same generic and boring there s really nothing worth watching...\nthis film grate at the teeth and i m still wondering what the heck bill paxton was doing in this film and why the heck does...</code></pre></div>\n<h3 id=\"input-data-vào-doc2vec\" style=\"position:relative;\"><a href=\"#input-data-v%C3%A0o-doc2vec\" aria-label=\"input data vào doc2vec permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Input data vào Doc2vec</h3>\n<p>Doc2vec của gensim input một object <strong>LabeledSentence</strong>, gồm 1 tập các từ kèm theo label (id của paragraph), có format như sau:</p>\n<div class=\"gatsby-highlight\" data-language=\"py\"><pre class=\"language-py\"><code class=\"language-py\"><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token string\">'word1'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'word2'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'word3'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'lastword'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'label1'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span></code></pre></div>\n<p>Ta sẽ viết class <strong>LabeledLineSentence</strong> để đọc data <strong>txt</strong>, yield ra object <strong>LabeledSentence</strong> để <strong>gensim</strong> có thể hiểu.</p>\n<div class=\"gatsby-highlight\" data-language=\"py\"><pre class=\"language-py\"><code class=\"language-py\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">LabeledLineSentence</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">object</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> sources<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>sources <span class=\"token operator\">=</span> sources\n        \n        flipped <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span>\n        \n        <span class=\"token comment\"># make sure that keys are unique</span>\n        <span class=\"token keyword\">for</span> key<span class=\"token punctuation\">,</span> value <span class=\"token keyword\">in</span> sources<span class=\"token punctuation\">.</span>items<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">if</span> value <span class=\"token keyword\">not</span> <span class=\"token keyword\">in</span> flipped<span class=\"token punctuation\">:</span>\n                flipped<span class=\"token punctuation\">[</span>value<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>key<span class=\"token punctuation\">]</span>\n            <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n                <span class=\"token keyword\">raise</span> Exception<span class=\"token punctuation\">(</span><span class=\"token string\">'Non-unique prefix encountered'</span><span class=\"token punctuation\">)</span>\n    \n    <span class=\"token keyword\">def</span> <span class=\"token function\">__iter__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">for</span> source<span class=\"token punctuation\">,</span> prefix <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>sources<span class=\"token punctuation\">.</span>items<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">with</span> utils<span class=\"token punctuation\">.</span>smart_open<span class=\"token punctuation\">(</span>source<span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> fin<span class=\"token punctuation\">:</span>\n                <span class=\"token keyword\">for</span> item_no<span class=\"token punctuation\">,</span> line <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>fin<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                    <span class=\"token keyword\">yield</span> LabeledSentence<span class=\"token punctuation\">(</span>utils<span class=\"token punctuation\">.</span>to_unicode<span class=\"token punctuation\">(</span>line<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>prefix <span class=\"token operator\">+</span> <span class=\"token string\">'_%s'</span> <span class=\"token operator\">%</span> item_no<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    \n    <span class=\"token keyword\">def</span> <span class=\"token function\">to_array</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>sentences <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">for</span> source<span class=\"token punctuation\">,</span> prefix <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>sources<span class=\"token punctuation\">.</span>items<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">with</span> utils<span class=\"token punctuation\">.</span>smart_open<span class=\"token punctuation\">(</span>source<span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> fin<span class=\"token punctuation\">:</span>\n                <span class=\"token keyword\">for</span> item_no<span class=\"token punctuation\">,</span> line <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>fin<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                    self<span class=\"token punctuation\">.</span>sentences<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>LabeledSentence<span class=\"token punctuation\">(</span>utils<span class=\"token punctuation\">.</span>to_unicode<span class=\"token punctuation\">(</span>line<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>prefix <span class=\"token operator\">+</span> <span class=\"token string\">'_%s'</span> <span class=\"token operator\">%</span> item_no<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>sentences\n    \n    <span class=\"token keyword\">def</span> <span class=\"token function\">sentences_perm</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        shuffled <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>sentences<span class=\"token punctuation\">)</span>\n        random<span class=\"token punctuation\">.</span>shuffle<span class=\"token punctuation\">(</span>shuffled<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> shuffled</code></pre></div>\n<p>Ok bây giờ chúng ta feed data files vào <strong>LabeledLineSentence</strong>, <strong>LabeledLineSentence</strong> input 1 dict với key là tên file, value là <strong>prefix</strong> của các sentences trong văn bản.  </p>\n<div class=\"gatsby-highlight\" data-language=\"py\"><pre class=\"language-py\"><code class=\"language-py\">sources <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token string\">'data/test-neg.txt'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'TEST_NEG'</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">'data/test-pos.txt'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'TEST_POS'</span><span class=\"token punctuation\">,</span> \n    <span class=\"token string\">'data/train-neg.txt'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'TRAIN_NEG'</span><span class=\"token punctuation\">,</span> \n    <span class=\"token string\">'data/train-pos.txt'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'TRAIN_POS'</span><span class=\"token punctuation\">,</span> \n    <span class=\"token string\">'data/train-unsup.txt'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'TRAIN_UNS'</span>\n<span class=\"token punctuation\">}</span>\n\nsentences <span class=\"token operator\">=</span> LabeledLineSentence<span class=\"token punctuation\">(</span>sources<span class=\"token punctuation\">)</span></code></pre></div>\n<h2 id=\"model\" style=\"position:relative;\"><a href=\"#model\" aria-label=\"model permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Model</h2>\n<h3 id=\"building-the-vocabulary-table\" style=\"position:relative;\"><a href=\"#building-the-vocabulary-table\" aria-label=\"building the vocabulary table permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Building the Vocabulary Table</h3>\n<p>Trước tiên <strong>Doc2vec</strong> yêu cầu build Vocabulary table, 1 tập chứa tất cả các từ, lọc bỏ các từ trùng lặp, thực hiện một số thống kê. Chúng ta có một số tham số như sau:</p>\n<ul>\n<li><em>min\\</em>count<em>: lọc bỏ tất cả các từ khỏi từ điển có số lần xuất hiện nhỏ hơn min\\</em>count.</li>\n<li><em>window</em>: khoảng cách tối đa của từ hiện tại và từ predicted. Tương tự window trong Skip-gram model.</li>\n<li><em>size</em>: số chiều của vector embedded. Thường từ trong khoảng 100-400 cho kết quả tối ưu.</li>\n<li><em>workers</em>: Số worker threads (set bằng số core của máy).</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"py\"><pre class=\"language-py\"><code class=\"language-py\">model <span class=\"token operator\">=</span> Doc2Vec<span class=\"token punctuation\">(</span>min_count<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> window<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> size<span class=\"token operator\">=</span><span class=\"token number\">100</span><span class=\"token punctuation\">,</span> sample<span class=\"token operator\">=</span><span class=\"token number\">1e</span><span class=\"token operator\">-</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span> negative<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> workers<span class=\"token operator\">=</span><span class=\"token number\">7</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>build_vocab<span class=\"token punctuation\">(</span>sentences<span class=\"token punctuation\">.</span>to_array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h3 id=\"training-doc2vec\" style=\"position:relative;\"><a href=\"#training-doc2vec\" aria-label=\"training doc2vec permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Training Doc2Vec</h3>\n<p>Mình sẽ train model với <strong>10 epochs</strong>. Nếu có thời gian bạn có thể chọn 20 hoặc 50 epochs. Mỗi epochs là một lần training trên toàn bộ dữ liệu.</p>\n<p>Phần này có thể tốn rất nhiều thời gian, tùy cấu hình máy bạn như thế nào.</p>\n<div class=\"gatsby-highlight\" data-language=\"py\"><pre class=\"language-py\"><code class=\"language-py\">model<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">(</span>sentences<span class=\"token punctuation\">.</span>sentences_perm<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> total_examples<span class=\"token operator\">=</span>model<span class=\"token punctuation\">.</span>corpus_count<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h3 id=\"inspecting-the-model\" style=\"position:relative;\"><a href=\"#inspecting-the-model\" aria-label=\"inspecting the model permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Inspecting the Model</h3>\n<p>Sau khi training, chúng ta có được các vector từ và vector văn bản. Tìm similarity của một từ (theo khoảng cách cosine).</p>\n<div class=\"gatsby-highlight\" data-language=\"py\"><pre class=\"language-py\"><code class=\"language-py\"><span class=\"token operator\">>></span><span class=\"token operator\">></span> model<span class=\"token punctuation\">.</span>most_similar<span class=\"token punctuation\">(</span><span class=\"token string\">'good'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token punctuation\">[</span><span class=\"token punctuation\">(</span><span class=\"token string\">u'great'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.7514600157737732</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n <span class=\"token punctuation\">(</span><span class=\"token string\">u'decent'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.7394523620605469</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n <span class=\"token punctuation\">(</span><span class=\"token string\">u'bad'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.6599287986755371</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n <span class=\"token punctuation\">(</span><span class=\"token string\">u'nice'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.6548842191696167</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n <span class=\"token punctuation\">(</span><span class=\"token string\">u'solid'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.6304105520248413</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n <span class=\"token punctuation\">(</span><span class=\"token string\">u'fine'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.6300679445266724</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n <span class=\"token punctuation\">(</span><span class=\"token string\">u'excellent'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.619133710861206</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n <span class=\"token punctuation\">(</span><span class=\"token string\">u'terrific'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.5940879583358765</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n <span class=\"token punctuation\">(</span><span class=\"token string\">u'fantastic'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.5322197675704956</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n <span class=\"token punctuation\">(</span><span class=\"token string\">u'poor'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.5300629734992981</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span></code></pre></div>\n<p>Vector của một đoạn văn trong tập negative reviews:</p>\n<div class=\"gatsby-highlight\" data-language=\"py\"><pre class=\"language-py\"><code class=\"language-py\"><span class=\"token operator\">>></span><span class=\"token operator\">></span> model<span class=\"token punctuation\">.</span>docvecs<span class=\"token punctuation\">[</span><span class=\"token string\">'TRAIN_NEG_0'</span><span class=\"token punctuation\">]</span>\n\narray<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span> <span class=\"token operator\">-</span><span class=\"token number\">1.01556428e-01</span><span class=\"token punctuation\">,</span>  <span class=\"token operator\">-</span><span class=\"token number\">3.56465846e-01</span><span class=\"token punctuation\">,</span>   <span class=\"token number\">3.44622403e-01</span><span class=\"token punctuation\">,</span>\n         <span class=\"token number\">8.42040837e-01</span><span class=\"token punctuation\">,</span>   <span class=\"token number\">3.27622980e-01</span><span class=\"token punctuation\">,</span>  <span class=\"token operator\">-</span><span class=\"token number\">1.11577833e+00</span><span class=\"token punctuation\">,</span>\n        <span class=\"token operator\">-</span><span class=\"token number\">2.24954560e-01</span><span class=\"token punctuation\">,</span>  <span class=\"token operator\">-</span><span class=\"token number\">5.04830778e-01</span><span class=\"token punctuation\">,</span>  <span class=\"token operator\">-</span><span class=\"token number\">1.88524842e-01</span><span class=\"token punctuation\">,</span>\n         <span class=\"token number\">1.36966994e-02</span><span class=\"token punctuation\">,</span>  <span class=\"token operator\">-</span><span class=\"token number\">1.20956969e+00</span><span class=\"token punctuation\">,</span>  <span class=\"token operator\">-</span><span class=\"token number\">1.48627579e-01</span><span class=\"token punctuation\">,</span>\n        <span class=\"token operator\">-</span><span class=\"token number\">9.34836924e-01</span><span class=\"token punctuation\">,</span>  <span class=\"token operator\">-</span><span class=\"token number\">1.52438581e-01</span><span class=\"token punctuation\">,</span>   <span class=\"token number\">2.31746025e-03</span><span class=\"token punctuation\">,</span>\n         <span class=\"token number\">4.67331141e-01</span><span class=\"token punctuation\">,</span>   <span class=\"token number\">2.05392256e-01</span><span class=\"token punctuation\">,</span>   <span class=\"token number\">3.45028825e-02</span><span class=\"token punctuation\">,</span>\n         <span class=\"token number\">1.80151880e-01</span><span class=\"token punctuation\">,</span>  <span class=\"token operator\">-</span><span class=\"token number\">5.39694607e-01</span><span class=\"token punctuation\">,</span>  <span class=\"token operator\">-</span><span class=\"token number\">6.49884492e-02</span><span class=\"token punctuation\">,</span>\n         <span class=\"token number\">1.35365915e+00</span><span class=\"token punctuation\">,</span>  <span class=\"token operator\">-</span><span class=\"token number\">5.30167639e-01</span><span class=\"token punctuation\">,</span>   <span class=\"token number\">5.87864697e-01</span><span class=\"token punctuation\">,</span>\n         <span class=\"token number\">7.33038425e-01</span><span class=\"token punctuation\">,</span>   <span class=\"token number\">8.35742176e-01</span><span class=\"token punctuation\">,</span>   <span class=\"token number\">7.98877537e-01</span><span class=\"token punctuation\">,</span>\n         <span class=\"token number\">2.99303561e-01</span><span class=\"token punctuation\">,</span>   <span class=\"token number\">2.93371022e-01</span><span class=\"token punctuation\">,</span>  <span class=\"token operator\">-</span><span class=\"token number\">2.80979633e-01</span><span class=\"token punctuation\">,</span>\n         <span class=\"token number\">5.45228899e-01</span><span class=\"token punctuation\">,</span>   <span class=\"token number\">7.07931161e-01</span><span class=\"token punctuation\">,</span>  <span class=\"token operator\">-</span><span class=\"token number\">6.89087927e-01</span><span class=\"token punctuation\">,</span>\n         <span class=\"token number\">4.84656468e-02</span><span class=\"token punctuation\">,</span>  <span class=\"token operator\">-</span><span class=\"token number\">5.57627855e-03</span><span class=\"token punctuation\">,</span>   <span class=\"token number\">7.30554581e-01</span><span class=\"token punctuation\">,</span>\n        <span class=\"token operator\">-</span><span class=\"token number\">5.21582305e-01</span><span class=\"token punctuation\">,</span>   <span class=\"token number\">1.05067813e+00</span><span class=\"token punctuation\">,</span>  <span class=\"token operator\">-</span><span class=\"token number\">3.70394111e-01</span><span class=\"token punctuation\">,</span>\n         <span class=\"token number\">2.97508329e-01</span><span class=\"token punctuation\">,</span>   <span class=\"token number\">4.00131464e-01</span><span class=\"token punctuation\">,</span>  <span class=\"token operator\">-</span><span class=\"token number\">6.46517992e-01</span><span class=\"token punctuation\">,</span>\n         <span class=\"token number\">1.84185669e-01</span><span class=\"token punctuation\">,</span>   <span class=\"token number\">3.36585194e-01</span><span class=\"token punctuation\">,</span>  <span class=\"token operator\">-</span><span class=\"token number\">1.15013385e+00</span><span class=\"token punctuation\">,</span>\n         <span class=\"token number\">5.34893453e-01</span><span class=\"token punctuation\">,</span>   <span class=\"token number\">1.59992184e-02</span><span class=\"token punctuation\">,</span>  <span class=\"token operator\">-</span><span class=\"token number\">2.28792682e-01</span><span class=\"token punctuation\">,</span>\n         <span class=\"token number\">6.48893565e-02</span><span class=\"token punctuation\">,</span>   <span class=\"token number\">3.11440937e-02</span><span class=\"token punctuation\">,</span>   <span class=\"token number\">6.16704404e-01</span><span class=\"token punctuation\">,</span>\n        <span class=\"token operator\">-</span><span class=\"token number\">6.95472300e-01</span><span class=\"token punctuation\">,</span>   <span class=\"token number\">3.94805223e-02</span><span class=\"token punctuation\">,</span>   <span class=\"token number\">2.85410255e-01</span><span class=\"token punctuation\">,</span>\n        <span class=\"token operator\">-</span><span class=\"token number\">9.06684458e-01</span><span class=\"token punctuation\">,</span>  <span class=\"token operator\">-</span><span class=\"token number\">1.28736183e-01</span><span class=\"token punctuation\">,</span>  <span class=\"token operator\">-</span><span class=\"token number\">1.12453914e+00</span><span class=\"token punctuation\">,</span>\n         <span class=\"token number\">6.06737316e-01</span><span class=\"token punctuation\">,</span>   <span class=\"token number\">2.80621439e-01</span><span class=\"token punctuation\">,</span>  <span class=\"token operator\">-</span><span class=\"token number\">9.90474075e-02</span><span class=\"token punctuation\">,</span>\n        <span class=\"token operator\">-</span><span class=\"token number\">4.19577152e-01</span><span class=\"token punctuation\">,</span>   <span class=\"token number\">2.71253318e-01</span><span class=\"token punctuation\">,</span>  <span class=\"token operator\">-</span><span class=\"token number\">3.55639100e-01</span><span class=\"token punctuation\">,</span>\n        <span class=\"token operator\">-</span><span class=\"token number\">3.38494778e-01</span><span class=\"token punctuation\">,</span>   <span class=\"token number\">1.36651471e-01</span><span class=\"token punctuation\">,</span>  <span class=\"token operator\">-</span><span class=\"token number\">9.72368240e-01</span><span class=\"token punctuation\">,</span>\n        <span class=\"token operator\">-</span><span class=\"token number\">8.00259411e-01</span><span class=\"token punctuation\">,</span>  <span class=\"token operator\">-</span><span class=\"token number\">3.47543478e-01</span><span class=\"token punctuation\">,</span>   <span class=\"token number\">4.80288565e-01</span><span class=\"token punctuation\">,</span>\n        <span class=\"token operator\">-</span><span class=\"token number\">9.50436354e-01</span><span class=\"token punctuation\">,</span>  <span class=\"token operator\">-</span><span class=\"token number\">8.92068386e-01</span><span class=\"token punctuation\">,</span>   <span class=\"token number\">3.37435633e-01</span><span class=\"token punctuation\">,</span>\n         <span class=\"token number\">6.15804553e-01</span><span class=\"token punctuation\">,</span>   <span class=\"token number\">6.83737099e-01</span><span class=\"token punctuation\">,</span>  <span class=\"token operator\">-</span><span class=\"token number\">4.11141992e-01</span><span class=\"token punctuation\">,</span>\n         <span class=\"token number\">1.23218540e-03</span><span class=\"token punctuation\">,</span>   <span class=\"token number\">2.87384093e-01</span><span class=\"token punctuation\">,</span>  <span class=\"token operator\">-</span><span class=\"token number\">3.08767110e-01</span><span class=\"token punctuation\">,</span>\n        <span class=\"token operator\">-</span><span class=\"token number\">1.81789771e-01</span><span class=\"token punctuation\">,</span>   <span class=\"token number\">1.44422725e-01</span><span class=\"token punctuation\">,</span>  <span class=\"token operator\">-</span><span class=\"token number\">3.68610471e-01</span><span class=\"token punctuation\">,</span>\n        <span class=\"token operator\">-</span><span class=\"token number\">2.94102520e-01</span><span class=\"token punctuation\">,</span>  <span class=\"token operator\">-</span><span class=\"token number\">6.52851164e-01</span><span class=\"token punctuation\">,</span>  <span class=\"token operator\">-</span><span class=\"token number\">3.40763658e-01</span><span class=\"token punctuation\">,</span>\n         <span class=\"token number\">7.20147192e-01</span><span class=\"token punctuation\">,</span>  <span class=\"token operator\">-</span><span class=\"token number\">8.44810545e-01</span><span class=\"token punctuation\">,</span>  <span class=\"token operator\">-</span><span class=\"token number\">2.64881551e-01</span><span class=\"token punctuation\">,</span>\n         <span class=\"token number\">1.91416308e-01</span><span class=\"token punctuation\">,</span>   <span class=\"token number\">5.62043667e-01</span><span class=\"token punctuation\">,</span>   <span class=\"token number\">9.71307516e-01</span><span class=\"token punctuation\">,</span>\n         <span class=\"token number\">4.49034691e-01</span><span class=\"token punctuation\">,</span>  <span class=\"token operator\">-</span><span class=\"token number\">3.56171519e-01</span><span class=\"token punctuation\">,</span>  <span class=\"token operator\">-</span><span class=\"token number\">5.25792062e-01</span><span class=\"token punctuation\">,</span>\n        <span class=\"token operator\">-</span><span class=\"token number\">2.70297438e-01</span><span class=\"token punctuation\">,</span>   <span class=\"token number\">3.60254765e-01</span><span class=\"token punctuation\">,</span>   <span class=\"token number\">3.01170051e-01</span><span class=\"token punctuation\">,</span>\n        <span class=\"token operator\">-</span><span class=\"token number\">3.10191274e-01</span><span class=\"token punctuation\">,</span>  <span class=\"token operator\">-</span><span class=\"token number\">8.09229612e-02</span><span class=\"token punctuation\">,</span>  <span class=\"token operator\">-</span><span class=\"token number\">8.08758587e-02</span><span class=\"token punctuation\">,</span>\n         <span class=\"token number\">8.15131485e-01</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>float32<span class=\"token punctuation\">)</span></code></pre></div>\n<h3 id=\"saving-and-loading-models\" style=\"position:relative;\"><a href=\"#saving-and-loading-models\" aria-label=\"saving and loading models permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Saving and Loading Models</h3>\n<p>Lưu xuống và tái sử dụng</p>\n<div class=\"gatsby-highlight\" data-language=\"py\"><pre class=\"language-py\"><code class=\"language-py\">model<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span><span class=\"token string\">'./imdb.d2v'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>Khi sử dụng, model chỉ cần load lại</p>\n<div class=\"gatsby-highlight\" data-language=\"py\"><pre class=\"language-py\"><code class=\"language-py\">model <span class=\"token operator\">=</span> Doc2Vec<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span><span class=\"token string\">'./imdb.d2v'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h2 id=\"classifying-sentiments\" style=\"position:relative;\"><a href=\"#classifying-sentiments\" aria-label=\"classifying sentiments permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Classifying Sentiments</h2>\n<p>Từ các vector văn bản trên, ta có thể sử dụng chúng để huấn luyện các bộ phân lớp. Trước tiên mình extract các vector này từ <strong>Doc2vec</strong> ra. Ở trên chúng ta có <strong>25000</strong> đoạn training reviews (<em>12500 positive, 12500 negative</em>), tức chúng ta sẽ có 25000 vector.</p>\n<p>Chúng ta tạo 2 biến <strong>X_train</strong> và <strong>y_train</strong> để lưu lại các vectors và labels tương ứng.</p>\n<div class=\"gatsby-highlight\" data-language=\"py\"><pre class=\"language-py\"><code class=\"language-py\">X_train <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">25000</span><span class=\"token punctuation\">,</span> <span class=\"token number\">100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ny_train <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token number\">25000</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">12500</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    prefix_train_pos <span class=\"token operator\">=</span> <span class=\"token string\">'TRAIN_POS_'</span> <span class=\"token operator\">+</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span>\n    prefix_train_neg <span class=\"token operator\">=</span> <span class=\"token string\">'TRAIN_NEG_'</span> <span class=\"token operator\">+</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span>\n    X_train<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>docvecs<span class=\"token punctuation\">[</span>prefix_train_pos<span class=\"token punctuation\">]</span>\n    X_train<span class=\"token punctuation\">[</span><span class=\"token number\">12500</span> <span class=\"token operator\">+</span> i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>docvecs<span class=\"token punctuation\">[</span>prefix_train_neg<span class=\"token punctuation\">]</span>\n    y_train<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">1</span>\n    y_train<span class=\"token punctuation\">[</span><span class=\"token number\">12500</span> <span class=\"token operator\">+</span> i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">0</span></code></pre></div>\n<p><strong>X_train</strong> là một list các vector:</p>\n<div class=\"gatsby-highlight\" data-language=\"py\"><pre class=\"language-py\"><code class=\"language-py\"><span class=\"token operator\">>></span><span class=\"token operator\">></span> <span class=\"token keyword\">print</span> X_train\n\n<span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span> <span class=\"token number\">0.07835239</span> <span class=\"token operator\">-</span><span class=\"token number\">0.74710965</span>  <span class=\"token number\">0.69579625</span> <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">,</span>  <span class=\"token number\">1.26008689</span> <span class=\"token operator\">-</span><span class=\"token number\">0.20882945</span>\n   <span class=\"token number\">0.15453815</span><span class=\"token punctuation\">]</span>\n <span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">0.30765828</span> <span class=\"token operator\">-</span><span class=\"token number\">1.3621341</span>  <span class=\"token operator\">-</span><span class=\"token number\">0.04978399</span> <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">,</span>  <span class=\"token number\">1.82920146</span>  <span class=\"token number\">0.83890873</span>\n  <span class=\"token operator\">-</span><span class=\"token number\">1.24059582</span><span class=\"token punctuation\">]</span>\n <span class=\"token punctuation\">[</span> <span class=\"token number\">0.43396333</span>  <span class=\"token number\">0.55141008</span>  <span class=\"token number\">1.10285032</span> <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">0.00459967</span> <span class=\"token operator\">-</span><span class=\"token number\">1.20170486</span>\n   <span class=\"token number\">0.24269094</span><span class=\"token punctuation\">]</span>\n <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">,</span> \n <span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">0.0061076</span>   <span class=\"token number\">1.02311051</span>  <span class=\"token number\">1.14070487</span> <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">,</span>  <span class=\"token number\">0.43794197</span> <span class=\"token operator\">-</span><span class=\"token number\">1.44546068</span>\n   <span class=\"token number\">0.92352289</span><span class=\"token punctuation\">]</span>\n <span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">0.66359657</span> <span class=\"token operator\">-</span><span class=\"token number\">0.14818916</span> <span class=\"token operator\">-</span><span class=\"token number\">0.00780609</span> <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">0.23638545</span>  <span class=\"token number\">0.11614358</span>\n   <span class=\"token number\">0.30252352</span><span class=\"token punctuation\">]</span>\n <span class=\"token punctuation\">[</span> <span class=\"token number\">0.48667926</span>  <span class=\"token number\">0.21486095</span> <span class=\"token operator\">-</span><span class=\"token number\">0.06502845</span> <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">,</span>  <span class=\"token number\">0.73961246</span>  <span class=\"token number\">0.17024654</span>\n   <span class=\"token number\">0.49861109</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span></code></pre></div>\n<p><strong>y_train</strong> sẽ là một list các label tương ứng, <em>label 1: positive, label 0: negative</em>.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token operator\">>></span><span class=\"token operator\">></span> <span class=\"token keyword\">print</span> y_train\n<span class=\"token punctuation\">[</span> <span class=\"token number\">1</span><span class=\"token punctuation\">.</span>  <span class=\"token number\">1</span><span class=\"token punctuation\">.</span>  <span class=\"token number\">1</span><span class=\"token punctuation\">.</span> <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">,</span>  <span class=\"token number\">0</span><span class=\"token punctuation\">.</span>  <span class=\"token number\">0</span><span class=\"token punctuation\">.</span>  <span class=\"token number\">0</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">]</span></code></pre></div>\n<h3 id=\"testing-vectors\" style=\"position:relative;\"><a href=\"#testing-vectors\" aria-label=\"testing vectors permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Testing Vectors</h3>\n<p>Tương tự với các vector để test</p>\n<div class=\"gatsby-highlight\" data-language=\"py\"><pre class=\"language-py\"><code class=\"language-py\">X_test <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">25000</span><span class=\"token punctuation\">,</span> <span class=\"token number\">100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ny_test <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token number\">25000</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">12500</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    prefix_test_pos <span class=\"token operator\">=</span> <span class=\"token string\">'TEST_POS_'</span> <span class=\"token operator\">+</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span>\n    prefix_test_neg <span class=\"token operator\">=</span> <span class=\"token string\">'TEST_NEG_'</span> <span class=\"token operator\">+</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span>\n    X_test<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>docvecs<span class=\"token punctuation\">[</span>prefix_test_pos<span class=\"token punctuation\">]</span>\n    X_test<span class=\"token punctuation\">[</span><span class=\"token number\">12500</span> <span class=\"token operator\">+</span> i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>docvecs<span class=\"token punctuation\">[</span>prefix_test_neg<span class=\"token punctuation\">]</span>\n    y_test<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">1</span>\n    y_test<span class=\"token punctuation\">[</span><span class=\"token number\">12500</span> <span class=\"token operator\">+</span> i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">0</span></code></pre></div>\n<h3 id=\"classification\" style=\"position:relative;\"><a href=\"#classification\" aria-label=\"classification permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Classification</h3>\n<p>Từ đây bạn có thể sử dụng bất cứ thuật toán phân lớp nào, bạn có thể thực hiện tiếp bước model selection đến khi nào đạt kết quả tốt nhất. Ở đây mình sử dụng <strong>Logistic Regression</strong> và <strong>SVM</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"py\"><pre class=\"language-py\"><code class=\"language-py\"><span class=\"token operator\">>></span><span class=\"token operator\">></span> classifier <span class=\"token operator\">=</span> LogisticRegression<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token operator\">>></span><span class=\"token operator\">></span> classifier<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span>\n\nLogisticRegression<span class=\"token punctuation\">(</span>C<span class=\"token operator\">=</span><span class=\"token number\">1.0</span><span class=\"token punctuation\">,</span> class_weight<span class=\"token operator\">=</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> dual<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> fit_intercept<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n          intercept_scaling<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> max_iter<span class=\"token operator\">=</span><span class=\"token number\">100</span><span class=\"token punctuation\">,</span> multi_class<span class=\"token operator\">=</span><span class=\"token string\">'ovr'</span><span class=\"token punctuation\">,</span> n_jobs<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span>\n          penalty<span class=\"token operator\">=</span><span class=\"token string\">'l2'</span><span class=\"token punctuation\">,</span> random_state<span class=\"token operator\">=</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> solver<span class=\"token operator\">=</span><span class=\"token string\">'liblinear'</span><span class=\"token punctuation\">,</span> tol<span class=\"token operator\">=</span><span class=\"token number\">0.0001</span><span class=\"token punctuation\">,</span>\n          verbose<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> warm_start<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>Độ chính xác của thuật toán và confusion matrix:</p>\n<div class=\"gatsby-highlight\" data-language=\"py\"><pre class=\"language-py\"><code class=\"language-py\"><span class=\"token keyword\">def</span> <span class=\"token function\">plot_confusion_matrix</span><span class=\"token punctuation\">(</span>cm<span class=\"token punctuation\">,</span> classes<span class=\"token punctuation\">,</span>\n                          normalize<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span>\n                          title<span class=\"token operator\">=</span><span class=\"token string\">'Confusion matrix'</span><span class=\"token punctuation\">,</span>\n                          cmap<span class=\"token operator\">=</span>plt<span class=\"token punctuation\">.</span>cm<span class=\"token punctuation\">.</span>Blues<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    See full source and example: \n    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n    \n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"</span>\n    plt<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span>cm<span class=\"token punctuation\">,</span> interpolation<span class=\"token operator\">=</span><span class=\"token string\">'nearest'</span><span class=\"token punctuation\">,</span> cmap<span class=\"token operator\">=</span>cmap<span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span>title<span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>colorbar<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    tick_marks <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>classes<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>xticks<span class=\"token punctuation\">(</span>tick_marks<span class=\"token punctuation\">,</span> classes<span class=\"token punctuation\">,</span> rotation<span class=\"token operator\">=</span><span class=\"token number\">45</span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>yticks<span class=\"token punctuation\">(</span>tick_marks<span class=\"token punctuation\">,</span> classes<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">if</span> normalize<span class=\"token punctuation\">:</span>\n        cm <span class=\"token operator\">=</span> cm<span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span><span class=\"token string\">'float'</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> cm<span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> np<span class=\"token punctuation\">.</span>newaxis<span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Normalized confusion matrix\"</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Confusion matrix, without normalization'</span><span class=\"token punctuation\">)</span>\n\n    thresh <span class=\"token operator\">=</span> cm<span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> <span class=\"token number\">2</span><span class=\"token punctuation\">.</span>\n    <span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span> j <span class=\"token keyword\">in</span> itertools<span class=\"token punctuation\">.</span>product<span class=\"token punctuation\">(</span><span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>cm<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>cm<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        plt<span class=\"token punctuation\">.</span>text<span class=\"token punctuation\">(</span>j<span class=\"token punctuation\">,</span> i<span class=\"token punctuation\">,</span> cm<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">,</span> j<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                 horizontalalignment<span class=\"token operator\">=</span><span class=\"token string\">\"center\"</span><span class=\"token punctuation\">,</span>\n                 color<span class=\"token operator\">=</span><span class=\"token string\">\"white\"</span> <span class=\"token keyword\">if</span> cm<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">,</span> j<span class=\"token punctuation\">]</span> <span class=\"token operator\">></span> thresh <span class=\"token keyword\">else</span> <span class=\"token string\">\"black\"</span><span class=\"token punctuation\">)</span>\n\n    plt<span class=\"token punctuation\">.</span>tight_layout<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'True label'</span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'Predicted label'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span> <span class=\"token string\">'Accuracy'</span><span class=\"token punctuation\">,</span> classifier<span class=\"token punctuation\">.</span>score<span class=\"token punctuation\">(</span>X_test<span class=\"token punctuation\">,</span> y_test<span class=\"token punctuation\">)</span>\ny_pred <span class=\"token operator\">=</span> classifier<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>X_test<span class=\"token punctuation\">)</span>\ncm <span class=\"token operator\">=</span> confusion_matrix<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">,</span> y_pred<span class=\"token punctuation\">,</span> labels<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nplot_confusion_matrix<span class=\"token punctuation\">(</span>cm<span class=\"token punctuation\">,</span> classes<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'neg'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'pos'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><em>Accuracy 0.86376</em><br />\n<em>Confusion matrix, without normalization</em> </p>\n<p><a href=\"https://3.bp.blogspot.com/-xZEUdBCyrEI/WdnN-V4iInI/AAAAAAAAnww/OqQ3uBxMCV0Eg0XkvsN7f-q2hkMZTrUvQCK4BGAYYCw/s1600/confusion_matrix_LR.png\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><img src=\"https://3.bp.blogspot.com/-xZEUdBCyrEI/WdnN-V4iInI/AAAAAAAAnww/OqQ3uBxMCV0Eg0XkvsN7f-q2hkMZTrUvQCK4BGAYYCw/s1600/confusion_matrix_LR.png\"></a></p>\n<p>Ok, chúng ta có <strong>87% accuracy</strong> cho sentiment analysis với <strong>Logistic Regression</strong>.</p>\n<p>Thử với SVM</p>\n<div class=\"gatsby-highlight\" data-language=\"py\"><pre class=\"language-py\"><code class=\"language-py\">classifier <span class=\"token operator\">=</span> SVC<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nclassifier<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span> <span class=\"token string\">'Accuracy'</span><span class=\"token punctuation\">,</span> classifier<span class=\"token punctuation\">.</span>score<span class=\"token punctuation\">(</span>X_test<span class=\"token punctuation\">,</span> y_test<span class=\"token punctuation\">)</span>\ny_pred <span class=\"token operator\">=</span> classifier<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>X_test<span class=\"token punctuation\">)</span>\ncm <span class=\"token operator\">=</span> confusion_matrix<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">,</span> y_pred<span class=\"token punctuation\">,</span> labels<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nplot_confusion_matrix<span class=\"token punctuation\">(</span>cm<span class=\"token punctuation\">,</span> classes<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'neg'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'pos'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><em>Accuracy 0.86708</em> <br />\n<em>Confusion matrix, without normalization</em></p>\n<p><a href=\"https://4.bp.blogspot.com/-vMs52b_9gZk/WdnOJG1wjhI/AAAAAAAAnw4/H10XIqYo_sMpAGS0tGWThPZkT0pkEJLHQCK4BGAYYCw/s1600/confusion_matrix_SVM.png\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><img src=\"https://4.bp.blogspot.com/-vMs52b_9gZk/WdnOJG1wjhI/AAAAAAAAnw4/H10XIqYo_sMpAGS0tGWThPZkT0pkEJLHQCK4BGAYYCw/s1600/confusion_matrix_SVM.png\"></a></p>\n<p>SVM cho kết quả tương tự, vẫn khá tốt <strong>~ 86%</strong>  </p>\n<h2 id=\"kết\" style=\"position:relative;\"><a href=\"#k%E1%BA%BFt\" aria-label=\"kết permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><strong>Kết</strong></h2>\n<p>Trong bài này mình đã:  </p>\n<ul>\n<li>Giới thiệu basic idea của Doc2vec.</li>\n<li>Các sử dụng Gensim để vector hóa một văn bản và sử dụng Logistic Regression cũng như SVM để phân lớp, đạt độ chính xác cao.</li>\n</ul>\n<p>Tham khảo:  </p>\n<ul>\n<li>Notebook và data bài viết: <strong><a href=\"https://github.com/duyetdev/doc2vec-sentiment\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://github.com/duyetdev/doc2vec-sentiment</a></strong></li>\n<li>Doc2vec tuts: <strong><a href=\"https://rare-technologies.com/doc2vec-tutorial/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://rare-technologies.com/doc2vec-tutorial/</a></strong></li>\n<li><strong><a href=\"https://github.com/linanqiu/word2vec-sentiments\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://github.com/linanqiu/word2vec-sentiments</a></strong></li>\n</ul>","fields":{"slug":"/2017/10/doc2vec-trong-sentiment-analysis.html","tagSlugs":["/tag/doc-2-vec/","/tag/neural-network/","/tag/python/","/tag/sentiment/","/tag/javascript/","/tag/nlp/","/tag/word-2-vec/","/tag/machine-learning/","/tag/sentimennt-analysis/"]},"frontmatter":{"date":"2017-10-08T14:33:00.001+07:00","description":"Doc2vec, ngoài từ (word), ta còn có thể biểu diễn các câu (sentences) thậm chí 1 đoạn văn bản (document). Khi đó, bạn có thể dễ dàng vector hóa cả một đoạn văn bản thành một vector có số chiều cố định và nhỏ, từ đó có thể chạy bất cứ thuật toán classification cơ bản nào trên các vector đó.","tags":["Doc2vec","Neural Network","Python","Sentiment","javascript","NLP","Word2vec","Machine Learning","Sentimennt Analysis"],"title":"Doc2vec trong Sentiment Analysis","fbCommentUrl":"http://blog.duyetdev.com/2017/10/doc2vec-trong-sentiment-analysis.html"}}},"pageContext":{"slug":"/2017/10/doc2vec-trong-sentiment-analysis.html"}}}