{"componentChunkName":"component---src-templates-post-template-js","path":"/2017/04/nlp-truyen-kieu-word2vec.html","result":{"data":{"markdownRemark":{"id":"053c6cdb-3c42-5347-9870-2b1cc35f4eda","html":"<p>Trong các dự án gần đây mình làm nhiều về Word2vec, khá có vẻ là useful trong việc biểu diễn word lên không gian vector (word embedding). Nói thêm về Word2vec, trong các dự án nghiên cứu W2V của Google còn khám phá được ra tính ngữ nghĩa, cú pháp của các từ ở một số mức độ nào đó. Ví dụ như bài toán <strong>King + Man - Woman = ?</strong> kinh điển dưới đây:  </p>\n<p><img src=\"https://1.bp.blogspot.com/-O7tdQkuYZ4U/WPOFQVmaFaI/AAAAAAAAkmE/B_LuJ3fxknYsAekzZCy5uOLez3znOiV9wCK4B/s1600/word2vectors.gif\"></p>\n<p>Sử dụng <strong>word2vec</strong> cho <a href=\"https://en.wikipedia.org/wiki/The_Tale_of_Kieu\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Truyện Kiều</a> (Nguyễn Du), tuy không phải là một dataset lớn, nhưng biết đâu sẽ tìm ra mối liên hệ “bí ẩn” nào đó giữa Kiều và Mã Giám Sinh. Hay thật sự có phải chữ <strong>“Tài”</strong> đi với chữ <strong>“Tai”</strong> như Nguyễn Du đã viết?  </p>\n<h2 id=\"word-vector-là-gì\" style=\"position:relative;\"><a href=\"#word-vector-l%C3%A0-g%C3%AC\" aria-label=\"word vector là gì permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Word vector là gì?</h2>\n<p>Trước tiên giới thiệu 1 chút về Word vector. Về cơ bản, đây chỉ là một vector trọng số, biểu diễn cho 1 từ, với số chiều cụ thể.  </p>\n<p>Ví dụ, 1-of-N (one-hot vector) sẽ mã hoá (encoding) các từ trong từ điển thành một vector có chiều dài N (tổng số lượng các từ trong từ điển). Giả sử từ điển của chúng ta chỉ có 5 từ: <strong>King, Queen, Man, Woman, và Child</strong>. Ta có thể biểu diễn từ “Queen” như bên dưới:</p>\n<p><a href=\"https://3.bp.blogspot.com/-avTgyW5ipsM/WPOGd7GiNMI/AAAAAAAAkmQ/zMVG_NJ-YOQGs3C4EYlaOt7Dqi-iw4l0wCK4B/s1600/word2vec-one-hot.png\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><img src=\"https://3.bp.blogspot.com/-avTgyW5ipsM/WPOGd7GiNMI/AAAAAAAAkmQ/zMVG_NJ-YOQGs3C4EYlaOt7Dqi-iw4l0wCK4B/s1600/word2vec-one-hot.png\"></a>\nẢnh: blog.acolyer.org</p>\n<p>Nhược điểm của cách biểu diễn này là ta không thu được nhiều ý nghĩa trong việc so sánh các từ với nhau ngoại trừ so sánh bằng, các từ có ý nghĩa hơn không được nhấn mạnh.  </p>\n<h2 id=\"word2vec\" style=\"position:relative;\"><a href=\"#word2vec\" aria-label=\"word2vec permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Word2vec</h2>\n<p>Ngược lại, word2vec biểu diễn các từ dưới dạng một phân bố quan hệ với các từ còn lại (distributed representation). Mỗi từ được biểu diễn bằng một vector có các phần tử mang giá trị là phân bố quan hệ của từ này đối với các từ khác trong từ điển.  </p>\n<p><img src=\"https://1.bp.blogspot.com/--U7neeCnIts/WPOG-XnmKYI/AAAAAAAAkmY/w12ZS3LLLqgmNFELDYBMaSnKH-zBa4sQgCK4B/s1600/word2vec-distributed-representation.png\">\nẢnh: blog.acolyer.org</p>\n<p>Với cách biểu diễn như vậy, người ta khám phá ra rằng các vector mang lại cho ta cả cú pháp và ngữ nghĩa ở một mức độ nào đó để máy tính hiểu.</p>\n<p>Ví dụ: </p>\n<ul>\n<li>x(apple) – x(apples) ≈ x(car) – x(cars)</li>\n<li>x(family) – x(families) ≈ x(car) – x(cars)</li>\n</ul>\n<p>Với <strong>x(apple)</strong> là <strong>vector</strong> của từ <strong><em>apple</em></strong>, …</p>\n<p><img src=\"https://4.bp.blogspot.com/-bAC2VBATSGE/WPOIKvgs-bI/AAAAAAAAkms/Z-JN1kYsAycl8sqXcNUdnh1aAzXZYzzFACK4B/s1600/word2vec-dr-fig-2.png\">\nẢnh: blog.acolyer.org</p>\n<p>Bạn có thể tìm hiểu kỹ hơn về Word2vec <strong><a href=\"https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">ở bài viết này</a></strong>.</p>\n<h2 id=\"chuẩn-bị-dataset-và-tiền-xử-lý\" style=\"position:relative;\"><a href=\"#chu%E1%BA%A9n-b%E1%BB%8B-dataset-v%C3%A0-ti%E1%BB%81n-x%E1%BB%AD-l%C3%BD\" aria-label=\"chuẩn bị dataset và tiền xử lý permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Chuẩn bị dataset và tiền xử lý</h2>\n<p>Mình tìm kiếm bộ full Truyện Kiều trên Google, lưu vào file <strong>truyen_kieu_data.txt</strong>. Bắt đầu tiền xử lý.</p>\n<h3 id=\"1-load-tất-cả-các-dòng-vào-data-frame-pandas\" style=\"position:relative;\"><a href=\"#1-load-t%E1%BA%A5t-c%E1%BA%A3-c%C3%A1c-d%C3%B2ng-v%C3%A0o-data-frame-pandas\" aria-label=\"1 load tất cả các dòng vào data frame pandas permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Load tất cả các dòng vào data frame Pandas</h3>\n<script src=\"https://gist.github.com/duyetdev/d7ef8efb03a7e79b61368da3f9a961e8.js\"></script>\n<h3 id=\"2-xử-lý-từng-dòng-xóa-số-dòng-bỏ-chấm-chấm-phẩy---các-dấu-dư-thừa\" style=\"position:relative;\"><a href=\"#2-x%E1%BB%AD-l%C3%BD-t%E1%BB%ABng-d%C3%B2ng-x%C3%B3a-s%E1%BB%91-d%C3%B2ng-b%E1%BB%8F-ch%E1%BA%A5m-ch%E1%BA%A5m-ph%E1%BA%A9y---c%C3%A1c-d%E1%BA%A5u-d%C6%B0-th%E1%BB%ABa\" aria-label=\"2 xử lý từng dòng xóa số dòng bỏ chấm chấm phẩy   các dấu dư thừa permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. Xử lý từng dòng: Xóa số dòng, bỏ chấm chấm, phẩy,  … các dấu dư thừa.</h3>\n<script src=\"https://gist.github.com/duyetdev/bb84042ca6da9b59a32bab7f19bbf8a9.js\"></script>\n<h2 id=\"tách-từ-sử-dụng-ngram\" style=\"position:relative;\"><a href=\"#t%C3%A1ch-t%E1%BB%AB-s%E1%BB%AD-d%E1%BB%A5ng-ngram\" aria-label=\"tách từ sử dụng ngram permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Tách từ sử dụng ngram</h2>\n<p>Để cho nhanh thay về tokenize tiếng Việt, mình sẽ sử dụng unigram (1-gram) và bigram (2-gram) để tách từ ra. </p>\n<p>Để cho dễ hiểu thì bigram sẽ tách câu sau thành:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>ngrams<span class=\"token punctuation\">(</span><span class=\"token string\">\"Trăm năm trong cõi người ta\"</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token operator\">></span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"Trăm năm\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"năm trong\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"trong cõi\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"cõi người\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"người ta\"</span><span class=\"token punctuation\">]</span></code></pre></div>\n<p>Với các bigram không có nghĩa như <em>“năm trong”, “trong cõi”</em>. Word2vec cho phép tham số <code class=\"language-text\">min_count</code>, tức những từ này xuất hiện ít hơn n sẽ bị loại bỏ, vì chúng không có ý nghĩa trong tiếng Việt.</p>\n<script src=\"https://gist.github.com/duyetdev/ee5348c6d449bc90073a827a42d02571.js\"></script>\n<h2 id=\"combine-data-và-word2vec-với-gensim-python\" style=\"position:relative;\"><a href=\"#combine-data-v%C3%A0-word2vec-v%E1%BB%9Bi-gensim-python\" aria-label=\"combine data và word2vec với gensim python permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Combine data và word2vec với Gensim Python</h2>\n<p>Đến đoạn hay, truy vấn, tìm những từ gần nhau.  </p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model<span class=\"token punctuation\">.</span>wv<span class=\"token punctuation\">.</span>similar_by_word<span class=\"token punctuation\">(</span><span class=\"token string\">\"thúy kiều\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># [('thâm', 0.9992734789848328),</span>\n<span class=\"token comment\">#  ('bụi', 0.9992575645446777),</span>\n<span class=\"token comment\">#  ('lẽ', 0.9992456436157227),</span>\n<span class=\"token comment\">#  ('bắt', 0.9992380142211914),</span>\n<span class=\"token comment\">#  ('ví', 0.9992336630821228),</span>\n<span class=\"token comment\">#  ('vẻ', 0.9992306232452393),</span>\n<span class=\"token comment\">#  ('sắc', 0.999223530292511),</span>\n<span class=\"token comment\">#  ('dao', 0.9992178678512573),</span>\n<span class=\"token comment\">#  ('phen', 0.9992178082466125),</span>\n<span class=\"token comment\">#  ('hơn', 0.999215841293335)]</span></code></pre></div>\n<p>=> ”<strong>Thâm</strong>”, Nguyễn Du thật thâm thúy khi ẩn dụ về <strong>Thúy Kiều</strong> :))  </p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model<span class=\"token punctuation\">.</span>wv<span class=\"token punctuation\">.</span>similar_by_word<span class=\"token punctuation\">(</span><span class=\"token string\">\"tài\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># [('thiên', 0.9996418356895447),</span>\n<span class=\"token comment\">#  ('dao', 0.9996212124824524),</span>\n<span class=\"token comment\">#  ('bể', 0.9995993375778198),</span>\n<span class=\"token comment\">#  ('muôn', 0.9995784163475037),</span>\n<span class=\"token comment\">#  ('xuôi', 0.9995668530464172),</span>\n<span class=\"token comment\">#  ('00', 0.9995592832565308),</span>\n<span class=\"token comment\">#  ('nát', 0.9995554685592651),</span>\n<span class=\"token comment\">#  ('danh', 0.9995527267456055),</span>\n<span class=\"token comment\">#  ('họa', 0.9995507597923279),</span>\n<span class=\"token comment\">#  ('chờ', 0.9995506405830383)]</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model<span class=\"token punctuation\">.</span>wv<span class=\"token punctuation\">.</span>similar_by_word<span class=\"token punctuation\">(</span><span class=\"token string\">\"tình\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># [('phụ', 0.9994543790817261),</span>\n<span class=\"token comment\">#  ('âu', 0.999447226524353),</span>\n<span class=\"token comment\">#  ('nhiêu', 0.9994118809700012),</span>\n<span class=\"token comment\">#  ('50', 0.9994039535522461),</span>\n<span class=\"token comment\">#  ('40', 0.9994016885757446),</span>\n<span class=\"token comment\">#  ('cam', 0.9993953108787537),</span>\n<span class=\"token comment\">#  ('quá', 0.9993941783905029),</span>\n<span class=\"token comment\">#  ('động', 0.9993934631347656),</span>\n<span class=\"token comment\">#  ('này đã', 0.999393105506897),</span>\n<span class=\"token comment\">#  ('nhân', 0.9993886947631836)]</span></code></pre></div>\n<p>=> <strong>Tình</strong> không <strong>phụ</strong> sao gọi là tình  </p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model<span class=\"token punctuation\">.</span>wv<span class=\"token punctuation\">.</span>similar_by_word<span class=\"token punctuation\">(</span><span class=\"token string\">\"đời\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># [('nợ', 0.9996878504753113),</span>\n<span class=\"token comment\">#  ('thì cũng', 0.9996579885482788),</span>\n<span class=\"token comment\">#  ('này đã', 0.9996303915977478),</span>\n<span class=\"token comment\">#  ('miệng', 0.9996291995048523),</span>\n<span class=\"token comment\">#  ('bình', 0.999627947807312),</span>\n<span class=\"token comment\">#  ('lối', 0.999624490737915),</span>\n<span class=\"token comment\">#  ('khéo', 0.9996232986450195),</span>\n<span class=\"token comment\">#  ('cũng là', 0.999621570110321),</span>\n<span class=\"token comment\">#  ('kia', 0.9996169209480286),</span>\n<span class=\"token comment\">#  ('nhỏ', 0.9996155500411987)]</span></code></pre></div>\n<p><strong>Đời</strong> là một cục <strong>nợ</strong> :D  </p>\n<h3 id=\"5-pca-và-visualization\" style=\"position:relative;\"><a href=\"#5-pca-v%C3%A0-visualization\" aria-label=\"5 pca và visualization permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>5. PCA và visualization</h3>\n<p>PCA giảm vector word từ 100 chiều về 2 chiều, để vẽ lên không gian 2 chiều.</p>\n<script src=\"https://gist.github.com/duyetdev/94776c9c4aeb7a18950e6deb799950ee.js\"></script>\n<h2 id=\"kết\" style=\"position:relative;\"><a href=\"#k%E1%BA%BFt\" aria-label=\"kết permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Kết</h2>\n<p>Word2vec chính xác khi với bộ copus thật lớn. Với ví dụ trên thực sự mục đính chỉ là vui là chính và để hiểu rõ hơn phần nào về NLP với Word2vec. Bạn nào có hứng thú có thể build các bộ Word2vec với dữ liệu cho tiếng Việt, với phần Tokenize và tiền xử lý chuẩn - word2vec sẽ hữu ích rất nhiều.  </p>\n<p>Tham khảo thêm:  </p>\n<ul>\n<li>Truyện Kiều Word2vec at Github: <a href=\"https://github.com/duyetdev/truyenkieu-word2vec\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://github.com/duyetdev/truyenkieu-word2vec</a></li>\n<li><a href=\"https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">The amazing power of word vectors</a></li>\n<li><a href=\"https://arxiv.org/pdf/1301.3781.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Efficient Estimation of Word Representations in Vector Space</a> – Mikolov et al. 2013</li>\n<li><a href=\"https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Distributed Representations of Words and Phrases and their Compositionality</a> – Mikolov et al. 2013</li>\n</ul>","fields":{"slug":"/2017/04/nlp-truyen-kieu-word2vec.html","tagSlugs":["/tag/data-engineer/","/tag/python/","/tag/javascript/","/tag/machine-learning/"]},"frontmatter":{"date":"2017-04-16T23:44:00.000+07:00","description":"Trong các dự án gần đây mình làm nhiều về Word2vec, khá có vẻ là useful trong việc biểu diễn word lên không gian vector (word embedding). Nói thêm về Word2vec, trong các dự án nghiên cứu W2V của Google còn khám phá được ra tính ngữ nghĩa, cú pháp của các từ ở một số mức độ nào đó","tags":["Data Engineer","Python","Javascript","Machine Learning"],"title":"NLP - Truyện Kiều Word2vec","fbCommentUrl":"http://blog.duyetdev.com/2017/04/nlp-truyen-kieu-word2vec.html"}}},"pageContext":{"slug":"/2017/04/nlp-truyen-kieu-word2vec.html"}}}