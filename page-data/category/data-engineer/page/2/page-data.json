{"componentChunkName":"component---src-templates-category-template-js","path":"/category/data-engineer/page/2","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"fields":{"categorySlug":"/category/data-engineer/","slug":"/2016/12/vntokenizer-tren-pyspark.html"},"frontmatter":{"date":"2016-12-14T08:00:00.001+07:00","description":"Trong blog này mình sẽ custom lại vn.vitk để có thể chạy như một thư viện lập trình, sử dụng ngôn ngữ python (trên PySpark và Jupyter Notebook).","category":"Data Engineer","title":"vnTokenizer trên PySpark","thumbnail":null}}},{"node":{"fields":{"categorySlug":"/category/data-engineer/","slug":"/2016/11/r-tren-jupiter-notebook-ubuntu-1404.html"},"frontmatter":{"date":"2016-11-22T23:53:00.000+07:00","description":"Jupyter Notebook là công cụ khá mạnh của lập trình viên Python và Data Science. Nếu dùng R, Jupyter cũng cho phép ta tích hợp R kernel vào Notebook một cách dễ dàng.","category":"Data Engineer","title":"R trên Jupiter Notebook (Ubuntu 14.04 / 14.10 / 16.04)","thumbnail":"https://4.bp.blogspot.com/-aQIMnwL9Gxc/WDR00IF9dqI/AAAAAAAAf9w/ZvplzJNUtI8vjWh2nF8_kVJZoYF3fHF9QCLcB/s1600/Screenshot%2Bfrom%2B2016-11-22%2B23-39-25.png"}}},{"node":{"fields":{"categorySlug":"/category/data-engineer/","slug":"/2016/09/spark-convert-text-csv-to-parquet.html"},"frontmatter":{"date":"2016-09-21T10:54:00.000+07:00","description":"Lưu trữ dữ liệu dưới dạng Columnar như Apache Parquet góp phần tăng hiệu năng truy xuất trên Spark lên rất nhiều lần. Bởi vì nó có thể tính toán và chỉ lấy ra 1 phần dữ liệu cần thiết (như 1 vài cột trên CSV), mà không cần phải đụng tới các phần khác của data row. Ngoài ra Parquet còn hỗ trợ flexible compression do đó tiết kiệm được rất nhiều không gian HDFS.","category":"Data Engineer","title":"Spark: Convert Text (CSV) to Parquet để tối ưu hóa Spark SQL và HDFS","thumbnail":"https://2.bp.blogspot.com/-e_wBjtB6Fl0/V-ID3ys6F9I/AAAAAAAAd_k/jRxF8H344KM_ywgsxVfQAPy3GDXAd1_fQCK4B/s1600/parquet-logo.png"}}},{"node":{"fields":{"categorySlug":"/category/data-engineer/","slug":"/2015/12/map-reduce-va-bai-toan-wordcount.html"},"frontmatter":{"date":"2015-12-02T21:58:00.001+07:00","description":"Map-Reduce là một giải pháp! Map-Reduce được phát minh bởi các kỹ sư Google để giải quyết bài toán xử lý một khối lượng dữ liệu cực lớn, vượt quá khả năng xử lý của một máy tính đơn có cấu hình khủng.","category":"Data Engineer","title":"Bigdata - Map-Reduce và bài toán Word Count","thumbnail":"https://3.bp.blogspot.com/-i_xNRnGm_pY/Vl8HH5-TM0I/AAAAAAAAKKU/K1W4w2i2f5E/s1600/big-data-cloud-e1383271750410-460x394.png"}}},{"node":{"fields":{"categorySlug":"/category/data-engineer/","slug":"/2015/08/cac-ky-thuat-crawler-rut-trich-du-lieu.html"},"frontmatter":{"date":"2015-08-08T17:11:00.001+07:00","description":"Nhân dịp tuyển sinh ĐH này, mình có project về thu thập dữ liệu tuyển sinh của các thí sinh trên trang của các trường ĐH. Project này mục tiêu là thu thập toàn bộ thông tin của thí sinh (SBD, tên, tuổi, điểm các môn, nguyện vọng các ngành, trường mà thí sinh nộp xét tuyển, ...). Điều oái oăm là mỗi trường công bố dữ liệu 1 cách hết sức ... tùm lum và tào lao.","category":"Data Engineer","title":"Nodejs - Các kỹ thuật Crawler, rút trích dữ liệu với Nodejs","thumbnail":"https://3.bp.blogspot.com/-Cwxzj6-qXVo/VcXRtQa3L4I/AAAAAAAACss/YD6WVCG84JE/s1600/nodejs-crawler.png"}}}]}},"pageContext":{"category":"Data Engineer","currentPage":2,"postsLimit":8,"postsOffset":16,"prevPagePath":"/category/data-engineer/page/1","nextPagePath":"//category/data-engineer/page/3","hasPrevPage":true,"hasNextPage":false}},"staticQueryHashes":["251939775","2672868365","401334301"]}