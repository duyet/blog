{"componentChunkName":"component---src-templates-post-template-js","path":"/2016/09/pyspark-thieu-thu-vien-python-tren-worker.html","result":{"data":{"markdownRemark":{"id":"8f32967f-fa2c-5e2a-a837-45c1896c8693","html":"<p>Apache Spark chạy trên Cluster, với Java thì đơn giản. Với Python thì package python phải được cài trên từng Node của Worker. Nếu không bạn sẽ gặp phải lỗi thiếu thư viện.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">import hi \nTraceback (most recent call last):\n  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;\nImportError: No module named hi</code></pre></div>\n<p>Spark có chức năng ship thư viện đến từng máy trong Cluster, tương tự chức năng <code class=\"language-text\">addJars</code> với Spark Java hoặc Scala.</p>\n<ol>\n<li>Nén toàn bộ dist-packages với các thư viện cần thiết thành file <code class=\"language-text\">py-package.zip</code></li>\n<li>Sử dụng Spark Submit kèm thêm tham số <code class=\"language-text\">--py-files &lt;path/to/zip&gt;</code></li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">./bin/spark-submit app.py --py-files=py-package.zip</code></pre></div>\n<p>Spark sẽ tự động load thư viện trong zip vào từng node con, công việc dễ thở hơn là cài vào từng máy.</p>\n<p>Ngoài ra cũng có thể sử dụng hàm <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.html?highlight=addpyfile#pyspark.SparkContext.addPyFile\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">sc.addPyFile</a></p>\n<p>Spark cũng hỗ trợ thư viện dạng file <code class=\"language-text\">.py</code> và <code class=\"language-text\">.egg</code>. Những thư viện nào sử dụng <code class=\"language-text\">setuptools</code> có thể dùng lệnh sau để đóng gói thành file <code class=\"language-text\">.egg</code></p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">python setup.py bdist_egg</code></pre></div>","fields":{"slug":"/2016/09/pyspark-thieu-thu-vien-python-tren-worker.html","tagSlugs":["/tag/data-engineer/","/tag/apache-spark/","/tag/python/","/tag/tutorials/","/tag/javascript/","/tag/spark/","/tag/javascript/","/tag/note/","/tag/big-data/","/tag/thủ-thuật/"]},"frontmatter":{"date":"2016-09-08T09:55:00.000+07:00","description":"Apache Spark chạy trên Cluster, với Java thì đơn giản. Với Python thì package python phải được cài trên từng Node của Worker. Nếu không bạn sẽ gặp phải lỗi thiếu thư viện.","tags":["Data Engineer","Apache Spark","Python","Tutorials","javascript","Spark","Javascript","note","Big Data","Thủ thuật"],"title":"PySpark - Thiếu thư viện Python trên Worker","fbCommentUrl":"none"}}},"pageContext":{"slug":"/2016/09/pyspark-thieu-thu-vien-python-tren-worker.html"}}}